/*
 * @(#)AVIWriter.java
 *
 * Copyright (c) 2011-2012 Werner Randelshofer, Goldau, Switzerland. All
 * rights reserved.
 *
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer. For details see
 * accompanying license terms.
 */
package com.videorecorder.video.avi;

import com.videorecorder.video.codec.Codec;
import com.videorecorder.video.codec.Registry;
import com.videorecorder.video.codec.TechSmithCodec;
import com.videorecorder.video.format.Format;
import com.videorecorder.video.format.FormatKey;
import com.videorecorder.video.io.ByteArrayImageOutputStream;
import com.videorecorder.video.nio.Buffer;
import com.videorecorder.video.nio.BufferFlag;
import java.awt.Dimension;
import java.awt.image.BufferedImage;
import java.awt.image.ColorModel;
import java.awt.image.IndexColorModel;
import java.io.File;
import java.io.IOException;
import java.nio.ByteOrder;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.EnumSet;
import java.util.LinkedList;
import javax.imageio.stream.FileImageOutputStream;
import javax.imageio.stream.ImageOutputStream;
import static com.videorecorder.video.format.FormatKey.EncodingKey;
import static com.videorecorder.video.format.FormatKey.FrameRateKey;
import static com.videorecorder.video.format.FormatKey.KeyFrameIntervalKey;
import static com.videorecorder.video.format.FormatKey.MIME_AVI;
import static com.videorecorder.video.format.FormatKey.MediaTypeKey;
import static com.videorecorder.video.format.FormatKey.MimeTypeKey;
import static com.videorecorder.video.format.VideoFormatKeys.CompressionLevelKey;
import static com.videorecorder.video.format.VideoFormatKeys.DataClassKey;
import static com.videorecorder.video.format.VideoFormatKeys.DepthKey;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_AVI_DIB;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_AVI_RLE;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_BUFFERED_IMAGE;
import static com.videorecorder.video.format.VideoFormatKeys.FixedFrameRateKey;
import static com.videorecorder.video.format.VideoFormatKeys.HeightKey;
import static com.videorecorder.video.format.VideoFormatKeys.QualityKey;
import static com.videorecorder.video.format.VideoFormatKeys.WidthKey;
import static com.videorecorder.video.nio.BufferFlag.DISCARD;
import static com.videorecorder.video.nio.BufferFlag.KEYFRAME;

/**
 * Provides low-level support for writing already encoded audio and video
 * samples into an AVI 1.0 file. <p> The length of an AVI 1.0 file is limited to
 * 1 GB. This class supports lengths of up to 4 GB, but such files may not work
 * on all players. <p> For detailed information about the AVI 1.0 file format
 * see:<br> <a
 * href="http://msdn.microsoft.com/en-us/library/ms779636.aspx">msdn.microsoft.com
 * AVI RIFF</a><br> <a
 * href="http://www.microsoft.com/whdc/archive/fourcc.mspx">www.microsoft.com
 * FOURCC for Video Compression</a><br> <a
 * href="http://www.saettler.com/RIFFMCI/riffmci.html">www.saettler.com
 * RIFF</a><br>
 *
 * @author Werner Randelshofer
 * @version $Id: AVIWriter.java 306 2013-01-04 16:19:29Z werner $
 */
public class AVIWriter {

    /**
     * Chunk IDs.
     */
    protected final static int RIFF_ID =0x52494646;// "RIFF"
    protected final static int AVI_ID = 0x41564920;// "AVI "
    protected final static int LIST_ID = 0x4c495354;// "LIST"
    protected final static int MOVI_ID = 0x6d6f7669;// "movi"
    protected final static int HDRL_ID = 0x6864726c;// "hdrl"
    protected final static int AVIH_ID = 0x61766968;// "avih"
    protected final static int STRL_ID = 0x7374726c;// "strl"
    protected final static int STRH_ID = 0x73747268;// "strh"
    protected final static int STRN_ID = 0x7374726e;// "strn"
    protected final static int STRF_ID = 0x73747266;// "strf"
    protected final static int IDX1_ID = 0x69647831;// "idx1"
    protected final static int PC_ID = 0x00007063;// "??pc"
    protected final static int DB_ID = 0x00006462;// "??db"
    protected final static int DC_ID = 0x00006463;// "??dc"

    /**
     * Indicates this video stream contains palette changes. This flag warns the
     * playback software that it will need to animate the palette.
     */
    public final static int STRH_FLAG_VIDEO_PALETTE_CHANGES = 0x00010000;

    /**
     * Underlying output stream.
     */
    protected ImageOutputStream out;

    /**
     * The offset in the underlying ImageOutputStream. Normally this is 0 unless
     * the underlying stream already contained data when it was passed to the
     * constructor.
     */
    protected long streamOffset;

    /**
     * The states of the movie output stream.
     */
    protected enum States {

        STARTED, FINISHED, CLOSED
    }

    /**
     * The current state of the movie output stream.
     */
    protected States state = States.FINISHED;

    /**
     * This chunk holds the whole AVI content.
     */
    protected CompositeChunk aviChunk;

    /**
     * This chunk holds the movie frames.
     */
    protected CompositeChunk moviChunk;

    /**
     * This chunk holds the AVI Main Header.
     */
    protected FixedSizeDataChunk avihChunk;

    ArrayList<Sample> idx1 = new ArrayList<>();

    /**
     * Creates a new AVI writer.
     *
     * @param file the output file
     */
    public AVIWriter(File file) throws IOException {
        if (file.exists()) {
            file.delete();
        }
        this.out = new FileImageOutputStream(file);
        out.setByteOrder(ByteOrder.LITTLE_ENDIAN);
        this.streamOffset = 0;
    }

    /**
     * Adds a track.
     *
     * @param vf The format of the track.
     * @return The track number.
     */
    public int addVideoTrack(Format vf) throws IOException {
        if (!vf.containsKey(EncodingKey)) {
            throw new IllegalArgumentException("EncodingKey missing in " + vf);
        }
        if (!vf.containsKey(FrameRateKey)) {
            throw new IllegalArgumentException("FrameRateKey missing in " + vf);
        }
        if (!vf.containsKey(WidthKey)) {
            throw new IllegalArgumentException("WidthKey missing in " + vf);
        }
        if (!vf.containsKey(HeightKey)) {
            throw new IllegalArgumentException("HeightKey missing in " + vf);
        }
        if (!vf.containsKey(DepthKey)) {
            throw new IllegalArgumentException("DepthKey missing in " + vf);
        }
        int tr = addVideoTrack(
            vf.get(EncodingKey),
            1,
            vf.get(FrameRateKey),
            vf.get(WidthKey),
            vf.get(HeightKey),
            vf.get(DepthKey),
            vf.get(KeyFrameIntervalKey, vf.get(FrameRateKey)),
            vf.get(CompressionLevelKey, TechSmithCodec.DEFAULT_COMPRESSION_LEVEL));
        setCompressionQuality(tr, vf.get(QualityKey, 1.0f));
        return tr;
    }

    /**
     * Adds a video track.
     *
     * @param fccHandler The 4-character code of the format.
     * @param scale The denominator of the sample rate.
     * @param rate The numerator of the sample rate.
     * @param width The width of a video image. Must be greater than 0.
     * @param height The height of a video image. Must be greater than 0.
     * @param depth The number of bits per pixel. Must be greater than 0.
     * @param syncInterval Interval for sync-samples. 0 = automatic. 1 = all frames
     * are keyframes. Values larger than 1 specify that for every n-th frame is
     * a keyframe.
     *
     * @return Returns the track index.
     *
     * @throws IllegalArgumentException if the width or the height is smaller
     * than 1.
     */
    public int addVideoTrack(String fccHandler, int scale, int rate, int width, int height, int depth, int syncInterval, int compressionLevel) throws IOException {
        ensureFinished();

        if (fccHandler == null || fccHandler.length() != 4) {
            throw new IllegalArgumentException("fccHandler must be 4 characters long:" + fccHandler);
        }

        VideoTrack vt = new VideoTrack(
            tracks.size(),
            typeToInt(fccHandler),
            new Format(MediaTypeKey, FormatKey.MediaType.VIDEO,
                MimeTypeKey, MIME_AVI,
                EncodingKey, fccHandler,
                DataClassKey, byte[].class,
                WidthKey, width,
                HeightKey, height,
                DepthKey, depth,
                FixedFrameRateKey, true,
                FrameRateKey, rate,
                KeyFrameIntervalKey, syncInterval,
                CompressionLevelKey, compressionLevel));
        vt.scale = scale;
        vt.rate = rate;
        vt.syncInterval = syncInterval;
        vt.frameLeft = 0;
        vt.frameTop = 0;
        vt.frameRight = width;
        vt.frameBottom = height;
        vt.bitCount = depth;
        vt.planes = 1; // must be 1

        if (depth == 4) {
            byte[] gray = new byte[16];
            for (int i = 0; i < gray.length; i++) {
                gray[i] = (byte) ((i << 4) | i);
            }
            vt.palette = new IndexColorModel(4, 16, gray, gray, gray);
        } else if (depth == 8) {
            byte[] gray = new byte[256];
            for (int i = 0; i < gray.length; i++) {
                gray[i] = (byte) i;
            }
            vt.palette = new IndexColorModel(8, 256, gray, gray, gray);
        }

        tracks.add(vt);
        return tracks.size() - 1;
    }

    /**
     * Encodes the provided image and writes its sample data into the specified
     * track.
     *
     * @param track The track index.
     * @param image The image of the video frame.
     *
     * @throws IllegalArgumentException if the dimension of the frame
     * does not match the dimension of the video.
     * @throws UnsupportedOperationException if the {@code MovieWriter} does not
     * have a built-in encoder for this video format.
     * @throws IOException if writing the sample data failed.
     */
    public void write(int track, BufferedImage image) throws IOException {
        if (isClosed()) {
            return;
        }

        ensureStarted();

        VideoTrack vt = tracks.get(track);
        if (vt.codec == null) {
            createCodec(track);
        }
        if (vt.codec == null) {
            throw new UnsupportedOperationException("No codec for this format: " + vt.format);
        }

        // The dimension of the image must match the dimension of the video track
        Format fmt = vt.format;
        if (fmt.get(WidthKey) != image.getWidth() || fmt.get(HeightKey) != image.getHeight()) {
            throw new IllegalArgumentException("Dimensions of image[" + vt.samples.size()
                    + "] (width=" + image.getWidth() + ", height=" + image.getHeight()
                    + ") differs from video format of track: " + fmt);
        }

        // Encode pixel data
        {
            if (vt.outputBuffer == null) {
                vt.outputBuffer = new Buffer();
            }

            boolean isKeyframe = vt.syncInterval == 0 ? false : vt.samples.size() % vt.syncInterval == 0;

            Buffer inputBuffer = new Buffer();
            inputBuffer.flags = (isKeyframe) ? EnumSet.of(KEYFRAME) : EnumSet.noneOf(BufferFlag.class);
            inputBuffer.data = image;
            vt.codec.process(inputBuffer, vt.outputBuffer);
            if (vt.outputBuffer.flags.contains(DISCARD)) {
                return;
            }

            // Encode palette data
            isKeyframe = vt.outputBuffer.flags.contains(KEYFRAME);
            boolean paletteChange = writePalette(track, image, isKeyframe);
            writeSample(track, (byte[]) vt.outputBuffer.data, vt.outputBuffer.offset, vt.outputBuffer.length, isKeyframe && !paletteChange);
        }
    }

    private boolean writePalette(int track, BufferedImage image, boolean isKeyframe) throws IOException {
        if ((image.getColorModel() instanceof IndexColorModel)) {
            return writePalette(track, (IndexColorModel) image.getColorModel(), isKeyframe);
        }
        return false;
    }

    private boolean writePalette(int track, IndexColorModel imgPalette, boolean isKeyframe) throws IOException {
        ensureStarted();

        VideoTrack vt = tracks.get(track);
        int imgDepth = vt.bitCount;
        ByteArrayImageOutputStream tmp = null;
        boolean paletteChange = false;
        switch (imgDepth) {
            case 4: {
                int[] imgRGBs = new int[16];
                imgPalette.getRGBs(imgRGBs);
                int[] previousRGBs = new int[16];
                if (vt.previousPalette == null) {
                    vt.previousPalette = vt.palette;
                }
                vt.previousPalette.getRGBs(previousRGBs);
                if (isKeyframe || !Arrays.equals(imgRGBs, previousRGBs)) {
                    paletteChange = true;
                    vt.previousPalette = imgPalette;
                    int first = 0;
                    int last = imgPalette.getMapSize() - 1;
                    tmp = new ByteArrayImageOutputStream(ByteOrder.LITTLE_ENDIAN);
                    tmp.writeByte(first);//bFirstEntry
                    tmp.writeByte(last - first + 1);//bNumEntries
                    tmp.writeShort(0);//wFlags

                    for (int i = first; i <= last; i++) {
                        tmp.writeByte((imgRGBs[i] >>> 16) & 0xff); // red
                        tmp.writeByte((imgRGBs[i] >>> 8) & 0xff); // green
                        tmp.writeByte(imgRGBs[i] & 0xff); // blue
                        tmp.writeByte(0); // reserved*/
                    }

                }
                break;
            }
            case 8: {
                int[] imgRGBs = new int[256];
                imgPalette.getRGBs(imgRGBs);
                int[] previousRGBs = new int[256];
                if (vt.previousPalette != null) {
                    vt.previousPalette.getRGBs(previousRGBs);
                }
                if (isKeyframe || !Arrays.equals(imgRGBs, previousRGBs)) {
                    paletteChange = true;
                    vt.previousPalette = imgPalette;
                    int first = 0;
                    int last = imgPalette.getMapSize() - 1;
                    tmp = new ByteArrayImageOutputStream(ByteOrder.LITTLE_ENDIAN);
                    tmp.writeByte(first); // bFirstEntry
                    tmp.writeByte(last - first + 1); // bNumEntries
                    tmp.writeShort(0); // wFlags
                    for (int i = first; i <= last; i++) {
                        tmp.writeByte((imgRGBs[i] >>> 16) & 0xff); // red
                        tmp.writeByte((imgRGBs[i] >>> 8) & 0xff); // green
                        tmp.writeByte(imgRGBs[i] & 0xff); // blue
                        tmp.writeByte(0); // reserved*/
                    }
                }

                break;
            }
        }
        if (tmp != null) {
            tmp.close();
            writePalette(track, tmp.toByteArray(), 0, (int) tmp.length(), isKeyframe);
        }
        return paletteChange;
    }

    /**
     * Sets the global color palette.
     */
    public void setPalette(int track, ColorModel palette) {
        if (palette instanceof IndexColorModel) {
            tracks.get(track).palette = (IndexColorModel) palette;
        }
    }

    private Codec createCodec(Format fmt) {
        return Registry.getInstance().getEncoder(fmt.prepend(MimeTypeKey, MIME_AVI));
    }

    private void createCodec(int track) {
        VideoTrack tr = tracks.get(track);
        Format fmt = tr.format;
        tr.codec = createCodec(fmt);
        if (tr.codec != null) {
            if (fmt.get(MediaTypeKey) == FormatKey.MediaType.VIDEO) {
                tr.codec.setInputFormat(fmt.prepend(
                        EncodingKey, ENCODING_BUFFERED_IMAGE,
                        DataClassKey, BufferedImage.class));
                if (null == tr.codec.setOutputFormat(
                        fmt.prepend(FixedFrameRateKey, true,
                                QualityKey, getCompressionQuality(track),
                                MimeTypeKey, MIME_AVI,
                                DataClassKey, byte[].class))) {
                    throw new UnsupportedOperationException("Track " + tr + " codec does not support format " + fmt + ". codec=" + tr.codec);
                }
            } else {
                tr.codec.setInputFormat(null);
                if (null == tr.codec.setOutputFormat(
                        fmt.prepend(FixedFrameRateKey, true,
                                QualityKey, getCompressionQuality(track),
                                MimeTypeKey, MIME_AVI,
                                DataClassKey, byte[].class))) {
                    throw new UnsupportedOperationException("Track " + tr + " codec " + tr.codec + " does not support format. " + fmt);
                }
            }
        }
    }

    /**
     * Gets the dimension of a track.
     */
    public Dimension getVideoDimension(int track) {
        VideoTrack vt = tracks.get(track);
        Format fmt = vt.format;
        return new Dimension(fmt.get(WidthKey), fmt.get(HeightKey));
    }

    /**
     * Sets the compression quality of a track. <p> A value of 0 stands for
     * "high compression is important" a value of 1 for "high image quality is
     * important". <p> Changing this value affects the encoding of video frames
     * which are subsequently written into the track. Frames which have already
     * been written are not changed. <p> This value has no effect on videos
     * encoded with lossless encoders such as the PNG format. <p> The default
     * value is 0.97.
     *
     * @param newValue the new video quality
     */
    public void setCompressionQuality(int track, float newValue) {
        VideoTrack vt = tracks.get(track);
        vt.videoQuality = newValue;
    }

    /**
     * Returns the compression quality of a track.
     *
     * @return compression quality
     */
    public float getCompressionQuality(int track) {
        return tracks.get(track).videoQuality;
    }

    /**
     * Sets the state of the QuickTimeOutputStream to started. <p> If the state
     * is changed by this method, the prolog is written.
     */
    protected void ensureStarted() throws IOException {
        if (state != States.STARTED) {
            writeProlog();
            state = States.STARTED;
        }
    }

    /**
     * Sets the state of the QuickTimeOutpuStream to finished. <p> If the state
     * is changed by this method, the prolog is written.
     */
    protected void ensureFinished() {
        if (state != States.FINISHED) {
            throw new IllegalStateException("Writer is in illegal state for this operation.");
        }
    }

    /**
     * Writes an already encoded palette change into the specified track. <p> If
     * a track contains palette changes, then all key frames must be immediately
     * preceeded by a palette change chunk which also is a key frame. If a key
     * frame is not preceeded by a key frame palette change chunk, it will be
     * downgraded to a delta frame.
     *
     * @throws IllegalArgumentException if the track is not a video track.
     */
    public void writePalette(int track, byte[] data, int off, int len, boolean isKeyframe) throws IOException {
        VideoTrack vt = tracks.get(track);
        if (!isKeyframe && vt.samples.isEmpty()) {
            throw new IllegalStateException("The first sample in a track must be a keyframe.");
        }

        vt.flags |= STRH_FLAG_VIDEO_PALETTE_CHANGES;

        DataChunk paletteChangeChunk = new DataChunk(vt.twoCC | PC_ID);
        long offset = getRelativeStreamPosition();
        ImageOutputStream pOut = paletteChangeChunk.getOutputStream();
        pOut.write(data, off, len);
        moviChunk.add(paletteChangeChunk);
        paletteChangeChunk.finish();
        long length = getRelativeStreamPosition() - offset;
        Sample s = new Sample(paletteChangeChunk.chunkType, 0, offset, length, isKeyframe);
        vt.addSample(s);
        idx1.add(s);
        //tr.length+=0;  Length is not affected by this chunk!
        offset = getRelativeStreamPosition();
    }

    /**
     * Writes an already encoded sample from a byte array into a track. <p> This
     * method does not inspect the contents of the samples. The contents has to
     * match the format and dimensions of the media in this track. <p> If a
     * track contains palette changes, then all key frames must be immediately
     * preceeded by a palette change chunk. If a key frame is not preceeded by a
     * palette change chunk, it will be downgraded to a delta frame.
     *
     * @param track The track index.
     * @param data The encoded sample data.
     * @param off The startTime offset in the data.
     * @param len The number of bytes to write.
     * @param isKeyframe Whether the sample is a sync sample (keyframe).
     *
     * @throws IllegalArgumentException if the duration is less than 1.
     * @throws IOException if writing the sample data failed.
     */
    public void writeSample(int track, byte[] data, int off, int len, boolean isKeyframe) throws IOException {
        ensureStarted();
        VideoTrack tr = tracks.get(track);

        // The first sample in a track is always a key frame
        if (!isKeyframe && tr.samples.isEmpty()) {
            throw new IllegalStateException("The first sample in a track must be a keyframe.\nTrack="+track+", "+tr.format);
        }

        // If a stream has palette changes, then only palette change samples can
        // be marked as keyframe.
        if (isKeyframe && 0 != (tr.flags & STRH_FLAG_VIDEO_PALETTE_CHANGES)) {
            throw new IllegalStateException("Only palette changes can be marked as keyframe.\nTrack="+track+", "+tr.format);
        }

        DataChunk dc = new DataChunk(tr.getSampleChunkFourCC(), len);
        moviChunk.add(dc);
        ImageOutputStream mdatOut = dc.getOutputStream();
        long offset = getRelativeStreamPosition();
        mdatOut.write(data, off, len);
        long length = getRelativeStreamPosition() - offset;
        dc.finish();
        Sample s = new Sample(dc.chunkType, 1, offset, length, isKeyframe);
        tr.addSample(s);
        idx1.add(s);
        if (getRelativeStreamPosition() > 1L << 32) {
            throw new IOException("AVI file is larger than 4 GB");
        }
    }

    /**
     * Indicates whether the track is closed or finished.
     */
    public boolean isClosed() {
        return state == States.CLOSED;
    }

    /**
     * Closes the stream.
     *
     * @exception IOException if an I/O error has occurred
     */
    public void close() throws IOException {
        if (state == States.STARTED) {
            finish();
        }
        if (state != States.CLOSED) {
            out.close();
            state = States.CLOSED;
        }
    }

    /**
     * Finishes writing the contents of the AVI output stream without closing
     * the underlying stream. Use this method when applying multiple filters in
     * succession to the same output stream.
     *
     * @exception IllegalStateException if the dimension of the video track has
     * not been specified or determined yet.
     * @exception IOException if an I/O exception has occurred
     */
    public void finish() throws IOException {
        ensureOpen();
        if (state != States.FINISHED) {
            moviChunk.finish();
            writeEpilog();
            state = States.FINISHED;
        }
    }

    /**
     * Check to make sure that this stream has not been closed
     */
    private void ensureOpen() throws IOException {
        if (state == States.CLOSED) {
            throw new IOException("Stream closed");
        }
    }

    private void writeProlog() throws IOException {
        // The file has the following structure:
        //
        // .RIFF AVI
        // ..avih (AVI Header Chunk)
        // ..LIST strl (for each track)
        // ...strh (Stream Header Chunk)
        // ...strf (Stream Format Chunk)
        // ...**** (Extra Stream Header Chunks)
        // ...strn (Stream Name Chunk)
        // ..LIST movi
        // ...00dc (Compressed video data chunk in Track 00, repeated for each frame)
        // ..idx1 (List of video data chunks and their location in the file)

        // The RIFF AVI Chunk holds the complete movie
        aviChunk = new CompositeChunk(RIFF_ID, AVI_ID);
        CompositeChunk hdrlChunk = new CompositeChunk(LIST_ID, HDRL_ID);

        // Write empty AVI Main Header Chunk - we fill the data in later
        aviChunk.add(hdrlChunk);
        avihChunk = new FixedSizeDataChunk(AVIH_ID, 56);
        avihChunk.seekToEndOfChunk();
        hdrlChunk.add(avihChunk);

        // Write empty AVI Stream Header Chunk - we fill the data in later
        for (VideoTrack tr : tracks) {

            CompositeChunk strlChunk = new CompositeChunk(LIST_ID, STRL_ID);
            hdrlChunk.add(strlChunk);

            tr.strhChunk = new FixedSizeDataChunk(STRH_ID, 56);
            tr.strhChunk.seekToEndOfChunk();
            strlChunk.add(tr.strhChunk);

            tr.strfChunk = new FixedSizeDataChunk(STRF_ID, tr.getSTRFChunkSize());
            tr.strfChunk.seekToEndOfChunk();
            strlChunk.add(tr.strfChunk);

            if (tr.name != null) {
                byte[] data = (tr.name + "\u0000").getBytes("ASCII");
                DataChunk d = new DataChunk(STRN_ID,
                        data.length);
                ImageOutputStream dout = d.getOutputStream();
                dout.write(data);
                d.finish();
                strlChunk.add(d);
            }
        }

        moviChunk = new CompositeChunk(LIST_ID, MOVI_ID);
        aviChunk.add(moviChunk);
    }

    private void writeEpilog() throws IOException {

        ImageOutputStream d;

        /* Create Idx1 Chunk and write data
         * -------------
         typedef struct _avioldindex {
         FOURCC  fcc;
         DWORD   cb;
         struct _avioldindex_entry {
         DWORD   dwChunkId;
         DWORD   flags;
         DWORD   dwOffset;
         DWORD   dwSize;
         } aIndex[];
         } AVIOLDINDEX;
         */
        {
            DataChunk idx1Chunk = new DataChunk(IDX1_ID);
            aviChunk.add(idx1Chunk);
            d = idx1Chunk.getOutputStream();
            long moviListOffset = moviChunk.offset + 8 + 8;

            {
                for (Sample s : idx1) {
                    d.setByteOrder(ByteOrder.BIG_ENDIAN);
                    d.writeInt(s.chunkType); // dwChunkId
                    d.setByteOrder(ByteOrder.LITTLE_ENDIAN);
                    // Specifies a FOURCC that identifies a stream in the AVI file. The
                    // FOURCC must have the form 'xxyy' where xx is the stream number and yy
                    // is a two-character code that identifies the contents of the stream:
                    //
                    // Two-character code   Description
                    //  db                  Uncompressed video frame
                    //  dc                  Compressed video frame
                    //  header                  Palette change
                    //  wb                  Audio data

                    d.writeInt(((s.chunkType & 0xffff) == PC_ID ? 0x100 : 0x0)//
                            | (s.isKeyframe ? 0x10 : 0x0)); // flags
                    // Specifies a bitwise combination of zero or more of the following
                    // flags:
                    //
                    // Value    Name            Description
                    // 0x10     AVIIF_KEYFRAME  The data chunk is a key frame.
                    // 0x1      AVIIF_LIST      The data chunk is a 'rec ' list.
                    // 0x100    AVIIF_NO_TIME   The data chunk does not affect the timing of the
                    //                          stream. For example, this flag should be set for
                    //                          palette changes.

                    d.writeInt((int) (s.offset - moviListOffset)); // dwOffset
                    // Specifies the location of the data chunk in the file. The value
                    // should be specified as an offset, in bytes, from the startTime of the
                    // 'movi' list; however, in some AVI files it is given as an offset from
                    // the startTime of the file.

                    d.writeInt((int) (s.length)); // dwSize
                    // Specifies the size of the data chunk, in bytes.
                }

            }

            idx1Chunk.finish();
        }

        /* Write Data into AVI Main Header Chunk
         * -------------
         * The AVIMAINHEADER structure defines global information in an AVI file.
         * see http://msdn.microsoft.com/en-us/library/ms779632(VS.85).aspx
         typedef struct _avimainheader {
         FOURCC fcc;
         DWORD  cb;
         DWORD  dwMicroSecPerFrame;
         DWORD  dwMaxBytesPerSec;
         DWORD  dwPaddingGranularity;
         DWORD  flags;
         DWORD  dwTotalFrames;
         DWORD  initialFrames;
         DWORD  dwStreams;
         DWORD  dwSuggestedBufferSize;
         DWORD  dwWidth;
         DWORD  dwHeight;
         DWORD  dwReserved[4];
         } AVIMAINHEADER; */
        {
            avihChunk.seekToStartOfData();
            d = avihChunk.getOutputStream();

            // compute largest buffer size
            long largestBufferSize = 0;
            long duration = 0;
            for (VideoTrack tr : tracks) {
                long trackDuration = 0;
                for (Sample s : tr.samples) {
                    trackDuration += s.duration;
                }
                duration = Math.max(duration, trackDuration);
                for (Sample s : tr.samples) {
                    if (s.length > largestBufferSize) {
                        largestBufferSize = s.length;
                    }
                }
            }

            VideoTrack tt = tracks.get(0);

            d.writeInt((int) ((1000000L * tt.scale) / tt.rate)); // dwMicroSecPerFrame
            // Specifies the number of microseconds between frames.
            // This value indicates the overall timing for the file.

            d.writeInt((int)largestBufferSize); // dwMaxBytesPerSec
            // Specifies the approximate maximum data rate of the file.
            // This value indicates the number of bytes per second the system
            // must handle to present an AVI sequence as specified by the other
            // parameters contained in the main header and stream header chunks.

            d.writeInt(0); // dwPaddingGranularity
            // Specifies the alignment for data, in bytes. Pad the data to multiples
            // of this value.

            d.writeInt(0x10|0x100|0x800); // flags 
            // Contains a bitwise combination of zero or more of the following
            // flags:
            //
            // Value   Name         Description
            // 0x10    AVIF_HASINDEX Indicates the AVI file has an index.
            // 0x20    AVIF_MUSTUSEINDEX Indicates that application should use the
            //                      index, rather than the physical ordering of the
            //                      chunks in the file, to determine the order of
            //                      presentation of the data. For example, this flag
            //                      could be used to create a list of frames for
            //                      editing.
            // 0x100   AVIF_ISINTERLEAVED Indicates the AVI file is interleaved.
            // 0x800   AVIF_TRUST_CK_TYPE ???  
            // 0x1000  AVIF_WASCAPTUREFILE Indicates the AVI file is a specially
            //                      allocated file used for capturing real-time
            //                      video. Applications should warn the user before
            //                      writing over a file with this flag set because
            //                      the user probably defragmented this file.
            // 0x20000 AVIF_COPYRIGHTED Indicates the AVI file contains copyrighted
            //                      data and software. When this flag is used,
            //                      software should not permit the data to be
            //                      duplicated.

            /*long dwTotalFrames = 0;
             for (Track t : tracks) {
             dwTotalFrames += t.samples.size();
             }*/
            d.writeInt(tt.samples.size()); // dwTotalFrames
            // Specifies the total number of frames of data in the file.

            d.writeInt(0); // initialFrames
            // Specifies the initial frame for interleaved files. Noninterleaved
            // files should specify zero. If you are creating interleaved files,
            // specify the number of frames in the file prior to the initial frame
            // of the AVI sequence in this member.
            // To give the audio driver enough audio to work with, the audio data in
            // an interleaved file must be skewed from the video data. Typically,
            // the audio data should be moved forward enough frames to allow
            // approximately 0.75 seconds of audio data to be preloaded. The
            // dwInitialRecords member should be set to the number of frames the
            // audio is skewed. Also set the same value for the initialFrames
            // member of the AVISTREAMHEADER structure in the audio stream header

            d.writeInt(tracks.size()); // dwStreams
            // Specifies the number of streams in the file. For example, a file with
            // audio and video has two streams.

            d.writeInt((int) largestBufferSize); // dwSuggestedBufferSize
            // Specifies the suggested buffer size for reading the file. Generally,
            // this size should be large enough to contain the largest chunk in the
            // file. If set to zero, or if it is too small, the playback software
            // will have to reallocate memory during playback, which will reduce
            // performance. For an interleaved file, the buffer size should be large
            // enough to read an entire record, and not just a chunk.
            {
                int width = 0, height = 0;
                for (VideoTrack tr : tracks) {
                    width = Math.max(width, Math.max(tr.frameLeft, tr.frameRight));
                    height = Math.max(height, Math.max(tr.frameTop, tr.frameBottom));
                }
                d.writeInt(width); // dwWidth
                // Specifies the width of the AVI file in pixels.

                d.writeInt(height); // dwHeight
                // Specifies the height of the AVI file in pixels.
            }
            d.writeInt(0); // dwReserved[0]
            d.writeInt(0); // dwReserved[1]
            d.writeInt(0); // dwReserved[2]
            d.writeInt(0); // dwReserved[3]
            // Reserved. Set this array to zero.
        }

        for (VideoTrack vt : tracks) {
            /* Write Data into AVI Stream Header Chunk
             * -------------
             * The AVISTREAMHEADER structure contains information about one stream
             * in an AVI file.
             * see http://msdn.microsoft.com/en-us/library/ms779638(VS.85).aspx
             typedef struct _avistreamheader {
             FOURCC fcc;
             DWORD  cb;
             FOURCC fccType;
             FOURCC fccHandler;
             DWORD  flags;
             WORD   priority;
             WORD   language;
             DWORD  initialFrames;
             DWORD  scale;
             DWORD  rate;
             DWORD  startTime;
             DWORD  dwLength;
             DWORD  dwSuggestedBufferSize;
             DWORD  quality;
             DWORD  dwSampleSize;
             struct {
             short int left;
             short int top;
             short int right;
             short int bottom;
             }  rcFrame;
             } AVISTREAMHEADER;
             */
            vt.strhChunk.seekToStartOfData();
            d = vt.strhChunk.getOutputStream();
            d.setByteOrder(ByteOrder.BIG_ENDIAN);
            d.writeInt(typeToInt(VideoTrack.FOURCC));
            d.writeInt(vt.fccHandler); // fccHandler: specifies the codec
            d.setByteOrder(ByteOrder.LITTLE_ENDIAN);

            d.writeInt(vt.flags);
            // Contains any flags for the data stream. The bits in the high-order
            // word of these flags are specific to the type of data contained in the
            // stream. The following standard flags are defined:
            //
            // Value    Name        Description
            //          AVISF_DISABLED 0x00000001 Indicates this stream should not
            //                      be enabled by default.
            //          AVISF_VIDEO_PALCHANGES 0x00010000
            //                      Indicates this video stream contains
            //                      palette changes. This flag warns the playback
            //                      software that it will need to animate the
            //                      palette.

            d.writeShort(vt.priority); // priority: highest priority denotes default stream
            d.writeShort(vt.language); // language: language code (?)
            d.writeInt((int) vt.initialFrames); // initialFrames: how far audio data is ahead of the video frames
            d.writeInt((int) vt.scale); // scale: time scale
            d.writeInt((int) vt.rate); // rate: sample rate in scale units
            d.writeInt((int) vt.startTime); // startTime: starting time of stream
            d.writeInt((int) vt.length); // dwLength: length of stream ! WRONG

            long dwSuggestedBufferSize = 0;
            long dwSampleSize = -1; // => -1 indicates unknown
            for (Sample s : vt.samples) {
                if (s.length > dwSuggestedBufferSize) {
                    dwSuggestedBufferSize = s.length;
                }
                if (dwSampleSize == -1) {
                    dwSampleSize = s.length;
                } else if (dwSampleSize != s.length) {
                    dwSampleSize = 0;
                }
            }
            if (dwSampleSize == -1) {
                dwSampleSize = 0;
            }

            d.writeInt((int) dwSuggestedBufferSize); // dwSuggestedBufferSize
            // Specifies how large a buffer should be used to read this stream.
            // Typically, this contains a value corresponding to the largest chunk
            // present in the stream. Using the correct buffer size makes playback
            // more efficient. Use zero if you do not know the correct buffer size.

            d.writeInt(vt.quality); // quality
            // Specifies an indicator of the quality of the data in the stream.
            // Quality is represented as a number between 0 and 10,000.
            // For compressed data, this typically represents the value of the
            // quality parameter passed to the compression software. If set to â€“1,
            // drivers use the default quality value.

            d.writeInt((int) dwSampleSize); // dwSampleSize
            // Specifies the size of a single sample of data. This is set to zero
            // if the samples can vary in size. If this number is nonzero, then
            // multiple samples of data can be grouped into a single chunk within
            // the file. If it is zero, each sample of data (such as a video frame)
            // must be in a separate chunk. For video streams, this number is
            // typically zero, although it can be nonzero if all video frames are
            // the same size. For audio streams, this number should be the same as
            // the blockAlign member of the WAVEFORMATEX structure describing the
            // audio.

            d.writeShort(vt.frameLeft); // rcFrame.left
            d.writeShort(vt.frameTop); // rcFrame.top
            d.writeShort(vt.frameRight); // rcFrame.right
            d.writeShort(vt.frameBottom); // rcFrame.bottom
            // Specifies the destination rectangle for a text or video stream within
            // the movie rectangle specified by the dwWidth and dwHeight members of
            // the AVI main header structure. The rcFrame member is typically used
            // in support of multiple video streams. Set this rectangle to the
            // coordinates corresponding to the movie rectangle to update the whole
            // movie rectangle. Units for this member are pixels. The upper-left
            // corner of the destination rectangle is relative to the upper-left
            // corner of the movie rectangle.

            Format vf = vt.format;

            /* Write BITMAPINFOHEADR Data into AVI Stream Format Chunk
             /* -------------
             * see http://msdn.microsoft.com/en-us/library/ms779712(VS.85).aspx
             typedef struct tagBITMAPINFOHEADER {
             DWORD  biSize;
             LONG   width;
             LONG   height;
             WORD   planes;
             WORD   bitCount;
             DWORD  compression;
             DWORD  sizeImage;
             LONG   xPelsPerMeter;
             LONG   yPelsPerMeter;
             DWORD  clrUsed;
             DWORD  clrImportant;
             } BITMAPINFOHEADER;
             */
            vt.strfChunk.seekToStartOfData();
            d = vt.strfChunk.getOutputStream();
            d.writeInt(40); // biSize: number of bytes required by the structure.
            d.writeInt(vf.get(WidthKey)); // width
            d.writeInt(vf.get(HeightKey)); // height
            d.writeShort(1); // planes
            d.writeShort(vf.get(DepthKey)); // bitCount

            String enc = vf.get(EncodingKey);
            if (enc.equals(ENCODING_AVI_DIB)) {
                d.writeInt(0); // compression - BI_RGB for uncompressed RGB
            } else if (enc.equals(ENCODING_AVI_RLE)) {
                if (vf.get(DepthKey) == 8) {
                    d.writeInt(1); // compression - BI_RLE8
                } else if (vf.get(DepthKey) == 4) {
                    d.writeInt(2); // compression - BI_RLE4
                } else {
                    throw new UnsupportedOperationException("RLE only supports 4-bit and 8-bit images");
                }
            } else {
                d.setByteOrder(ByteOrder.BIG_ENDIAN);
                d.writeInt(typeToInt(vt.format.get(EncodingKey))); // compression
                d.setByteOrder(ByteOrder.LITTLE_ENDIAN);
            }

            if (enc.equals(ENCODING_AVI_DIB)) {
                d.writeInt(0); // sizeImage
            } else {
                if (vf.get(DepthKey) == 4) {
                    d.writeInt(vf.get(WidthKey) * vf.get(HeightKey) / 2); // sizeImage
                } else {
                    int bytesPerPixel = Math.max(1, vf.get(DepthKey) / 8);
                    d.writeInt(vf.get(WidthKey) * vf.get(HeightKey) * bytesPerPixel); // sizeImage
                }
            }

            d.writeInt(0); // xPelsPerMeter
            d.writeInt(0); // yPelsPerMeter

            d.writeInt(vt.palette == null ? 0 : vt.palette.getMapSize()); // clrUsed

            d.writeInt(0); // clrImportant

            if (vt.palette != null) {
                for (int i = 0, n = vt.palette.getMapSize(); i < n; ++i) {
                    /*
                     * typedef struct tagRGBQUAD {
                     BYTE rgbBlue;
                     BYTE rgbGreen;
                     BYTE rgbRed;
                     BYTE rgbReserved; // This member is reserved and must be zero.
                     } RGBQUAD;
                     */
                    d.write(vt.palette.getBlue(i));
                    d.write(vt.palette.getGreen(i));
                    d.write(vt.palette.getRed(i));
                    d.write(0);
                }
            }

        }

        // -----------------
        aviChunk.finish();
    }

    /**
     * The list of tracks in the file.
     */
    protected ArrayList<VideoTrack> tracks = new ArrayList<>();

    /**
     * AVI stores media data in sample chunks. A sample chunk may contain one or
     * more media samples. A media sample is a single element in a sequence of
     * time-ordered data.
     */
    protected static class Sample {

        int chunkType;

        /**
         * Offset of the sample chunk relative to the startTime of the AVI file.
         */
        long offset;

        /**
         * Data length of the sample chunk.
         */
        long length;

        /**
         * The number of media samples in the sample chunk.
         */
        int duration;

        /**
         * Whether the sample is a sync-sample.
         */
        boolean isKeyframe;

        long timeStamp;

        /**
         * Creates a new sample.
         *
         * @param duration The number of media samples contained in the sample
         * chunk.
         * @param offset The offset in the AVI stream.
         * @param length The length in the AVI stream.
         */
        public Sample(int chunkId, int duration, long offset, long length, boolean isSync) {
            this.chunkType = chunkId;
            this.duration = duration;
            this.offset = offset;
            this.length = length;
            this.isKeyframe = isSync;
        }
    }

    /**
     * Represents a video track in an AVI file. <p> The format of a video track
     * is defined in a "strf" chunk, which contains a {@code BITMAPINFOHEADER}
     * struct.
     *
     * </pre> //---------------------- // AVI Bitmap Info Header //
     * ---------------------- typedef struct { BYTE blue; BYTE green; BYTE red;
     * BYTE reserved; } RGBQUAD;
     *
     * // Values for this enum taken from: //
     * http://www.fourcc.org/index.php?http%3A//www.fourcc.org/rgb.php enum {
     * BI_RGB = 0x00000000, RGB = 0x32424752, // Alias for BI_RGB BI_RLE8 =
     * 0x01000000, RLE8 = 0x38454C52, // Alias for BI_RLE8 BI_RLE4 = 0x00000002,
     * RLE4 = 0x34454C52, // Alias for BI_RLE4 BI_BITFIELDS = 0x00000003, raw =
     * 0x32776173, RGBA = 0x41424752, RGBT = 0x54424752, cvid = "cvid" }
     * bitmapCompression;
     *
     * typedef struct { DWORD structSize; // Specifies the number of bytes
     * required by the structure. LONG width; // Specifies the width of the
     * bitmap. // - For RGB formats, the width is specified in pixels. // - The
     * same is true for YUV formats if the bitdepth is an even power // of 2. //
     * - For YUV formats where the bitdepth is not an even power of 2, //
     * however, the width is specified in bytes. // Decoders and video sources
     * should propose formats where "width" is // the width of the image. If the
     * video renderer is using DirectDraw, it // modifies the format so that
     * "width" equals the stride of the surface, // and the "target" member of
     * the VIDEOINFOHEADER or VIDEOINFOHEADER2 // structure specifies the image
     * width. Then it proposes the modified // format using IPin::QueryAccept.
     * // For RGB and even-power-of-2 YUV formats, if the video renderer does //
     * not specify the stride, then round the width up to the nearst DWORD //
     * boundary to find the stride. LONG height; // Specifies the height of the
     * bitmap, in pixels. // - For uncompressed RGB bitmaps, if "height" is
     * positive, the bitmap // is a bottom-up DIB with the origin at the lower
     * left corner. If // "height" is negative, the bitmap is a top-down DIB
     * with the origin // at the upper left corner. // - For YUV bitmaps, the
     * bitmap is always top-down, regardless of the // sign of "height".
     * Decoders should offer YUV formats with postive // "height", but for
     * backward compatibility they should accept YUV // formats with either
     * positive or negative "height". // - For compressed formats, height must
     * be positive, regardless of // image orientation. WORD planes; //
     * Specifies the number of planes for the target device. This value must //
     * be set to 1. WORD bitCount; // Specifies the number of bits per pixel.
     * //DWORD enum bitmapCompression compression; FOURCC enum bitmapCompression
     * compression; // If the bitmap is compressed, this member is a FOURCC the
     * specifies // the compression. // Value Description // BI_RLE8 A
     * run-length encoded (RLE) format for bitmaps with 8 // bpp. The
     * compression format is a 2-byte format // consisting of a count byte
     * followed by a byte containing a color index. For more information, see
     * Bitmap Compression. // BI_RLE4 An RLE format for bitmaps with 4 bpp. The
     * compression // format is a 2-byte format consisting of a count byte //
     * followed by two word-length color indexes. For more // information, see
     * Bitmap Compression. // BI_JPEG Windows 98/Me, Windows 2000/XP: Indicates
     * that the // image is a JPEG image. // BI_PNG Windows 98/Me, Windows
     * 2000/XP: Indicates that the // image is a PNG image. // For uncompressed
     * formats, the following values are possible: // Value Description //
     * BI_RGB Uncompressed RGB. // BI_BITFIELDS Specifies that the bitmap is not
     * compressed and that // the color table consists of three DWORD color
     * masks // that specify the red, green, and blue components, //
     * respectively, of each pixel. This is valid when used // with 16- and
     * 32-bpp bitmaps. DWORD imageSizeInBytes; // Specifies the size, in bytes,
     * of the image. This can be set to 0 for // uncompressed RGB bitmaps. LONG
     * xPelsPerMeter; // Specifies the horizontal resolution, in pixels per
     * meter, of the // target device for the bitmap. LONG yPelsPerMeter; //
     * Specifies the vertical resolution, in pixels per meter, of the target //
     * device for the bitmap. DWORD numberOfColorsUsed; // Specifies the number
     * of color indices in the color table that are // actually used by the
     * bitmap DWORD numberOfColorsImportant; // Specifies the number of color
     * indices that are considered important // for displaying the bitmap. If
     * this value is zero, all colors are // important. RGBQUAD colors[]; // If
     * the bitmap is 8-bpp or less, the bitmap uses a color table, which //
     * immediately follows the BITMAPINFOHEADER. The color table consists of //
     * an array of RGBQUAD values. The size of the array is given by the //
     * "clrUsed" member. If "clrUsed" is zero, the array contains the // maximum
     * number of colors for the given bitdepth; that is, // 2^"bitCount" colors.
     * } BITMAPINFOHEADER;
     * </pre>
     */
    protected class VideoTrack {

        /**
         * The media format.
         */
        protected Format format;

        /**
         * List of samples.
         */
        protected ArrayList<Sample> samples;

        /**
         * Interval between sync samples (keyframes). 0 = automatic. 1 = write
         * all samples as sync samples. n = sync every n-th sample.
         */
        protected int syncInterval = 30;

        /**
         * The twoCC code is used for the ids of the chunks which hold the data
         * samples.
         */
        protected int twoCC;

        /**
         * {@code FOURCC} specifies the type of the data contained in the stream.
         * The following standard AVI values for video and audio are defined.
         *
         * FOURCC Description
         * 'auds'	Audio stream
         * 'mids'	MIDI stream
         * 'txts'	Text stream
         * 'vids'	Video stream
         */
        protected static final String FOURCC = "vids";

        /**
         * Optionally, contains a FOURCC that identifies a specific data
         * handler. The data handler is the preferred handler for the stream.
         * For audio and video streams, this specifies the codec for decoding
         * the stream.
         */
        protected int fccHandler;

        /**
         * Contains any flags for the data stream. The bits in the high-order
         * word of these flags are specific to the type of data contained in the
         * stream. The following standard flags are defined.
         *
         * Value	Description
         *
         * AVISF_DISABLED	0x00000001 Indicates this stream should not be enabled
         * by default.
         *
         * AVISF_VIDEO_PALCHANGES 0x00010000 Indicates this video stream
         * contains palette changes. This flag warns the playback software that
         * it will need to animate the palette.
         */
        protected int flags;

        /**
         * Specifies priority of a stream type. For example, in a file with
         * multiple audio streams, the one with the highest priority might be
         * the default stream.
         */
        protected int priority = 0;

        /**
         * Language tag.
         */
        protected int language = 0;

        /**
         * Specifies how far audio data is skewed ahead of the video frames in
         * interleaved files. Typically, this is about 0.75 seconds. If you are
         * creating interleaved files, specify the number of frames in the file
         * prior to the initial frame of the AVI sequence in this member. For
         * more information, see the remarks for the initialFrames member of the
         * AVIMAINHEADER structure.
         */
        protected long initialFrames = 0;

        /**
         * Used with rate to specify the time scale that this stream will use.
         * Dividing rate by scale gives the number of samples per second. For
         * video streams, this is the frame rate. For audio streams, this rate
         * corresponds to the time needed to play blockAlign bytes of audio,
         * which for PCM audio is the just the sample rate.
         */
        protected long scale = 1;

        /**
         * The rate of the media in scale units.
         */
        protected long rate = 30;

        /**
         * Specifies the starting time for this stream. The units are defined by
         * the rate and scale members in the main file header. Usually, this is
         * zero, but it can specify a delay time for a stream that does not
         * startTime concurrently with the file.
         */
        protected long startTime = 0;

        /**
         * Specifies the length of this stream. The units are defined by the
         * rate and scale members of the stream's header.
         */
        protected long length;

        /**
         * Specifies an indicator of the quality of the data in the stream.
         * Quality is represented as a number between 0 and 10,000. For
         * compressed data, this typically represents the value of the quality
         * parameter passed to the compression software. If set to â€“1, drivers
         * use the default quality value.
         */
        protected int quality = -1;

        /**
         * Specifies the destination rectangle for a text or video stream within
         * the movie rectangle specified by the dwWidth and dwHeight members of
         * the AVI main header structure. The rcFrame member is typically used
         * in support of multiple video streams. Set this rectangle to the
         * coordinates corresponding to the movie rectangle to update the whole
         * movie rectangle. Units for this member are pixels. The upper-left
         * corner of the destination rectangle is relative to the upper-left
         * corner of the movie rectangle.
         */
        int frameLeft;
        int frameTop;
        int frameRight;
        int frameBottom;

        /**
         * This chunk holds the AVI Stream Header.
         */
        protected FixedSizeDataChunk strhChunk;

        /**
         * This chunk holds the AVI Stream Format Header.
         */
        protected FixedSizeDataChunk strfChunk;

        /**
         * The optional name of the track.
         */
        protected String name;

        /**
         * The codec.
         */
        protected Codec codec;

        /**
         * The output buffer is used to store the output of the codec.
         */
        protected Buffer outputBuffer;

        /**
         * The video compression quality.
         */
        protected float videoQuality = 0.97f;

        /**
         * Index color model for RAW_RGB4 and RAW_RGB8 formats.
         */
        protected IndexColorModel palette;

        protected IndexColorModel previousPalette;

        /**
         * Specifies the number of planes for the target device. This value must
         * be set to 1.
         */
        int planes;

        /**
         * Specifies the number of bits per pixel (bpp). For uncompressed
         * formats, this value is the average number of bits per pixel. For
         * compressed formats, this value is the implied bit depth of the
         * uncompressed image, after the image has been decoded.
         */
        int bitCount;

        private int sampleChunkFourCC;

        public VideoTrack(int trackIndex, int fourCC, Format videoFormat) {
            twoCC = (('0'+trackIndex/10)<<24) | (('0'+trackIndex%10)<<16);

            this.fccHandler = fourCC;
            this.samples = new ArrayList<>();
            // this.extraHeaders = new ArrayList<>();
            this.format = videoFormat;
            sampleChunkFourCC = videoFormat != null && videoFormat.get(EncodingKey).equals(ENCODING_AVI_DIB) ? twoCC | DB_ID : twoCC | DC_ID;
        }

        public long getSTRFChunkSize() {
            return palette == null ? 40 : 40 + palette.getMapSize() * 4;

        }

        public int getSampleChunkFourCC() {
            return sampleChunkFourCC;
        }

        public void addSample(Sample s) {
            if (!samples.isEmpty()) {
                s.timeStamp = samples.get(samples.size() - 1).timeStamp + samples.get(samples.size() - 1).duration;
            }
            samples.add(s);
            length++;
        }
    }

    /**
     * Chunk base class.
     */
    protected abstract class Chunk {

        /**
         * The chunkType of the chunk. A String with the length of 4 characters.
         */
        protected int chunkType;

        /**
         * The offset of the chunk relative to the startTime of the
         * ImageOutputStream.
         */
        protected long offset;

        /**
         * Creates a new Chunk at the current position of the ImageOutputStream.
         *
         * @param chunkType The chunkType of the chunk. A string with a length
         * of 4 characters.
         */
        public Chunk(int chunkType) throws IOException {
            this.chunkType = chunkType;
            offset = getRelativeStreamPosition();
        }

        /**
         * Writes the chunk to the ImageOutputStream and disposes it.
         */
        public abstract void finish() throws IOException;

        /**
         * Returns the size of the chunk including the size of the chunk header.
         *
         * @return The size of the chunk.
         */
        public abstract long size();
    }

    /**
     * A CompositeChunk contains an ordered list of Chunks.
     */
    protected class CompositeChunk extends Chunk {

        /**
         * The type of the composite. A String with the length of 4 characters.
         */
        protected int compositeType;
        protected LinkedList<Chunk> children;
        protected boolean finished;

        /**
         * Creates a new CompositeChunk at the current position of the
         * ImageOutputStream.
         *
         * @param compositeType The type of the composite.
         * @param chunkType The type of the chunk.
         */
        public CompositeChunk(int compositeType, int chunkType) throws IOException {
            super(chunkType);
            this.compositeType = compositeType;
            out.writeLong(0); // make room for the chunk header
            out.writeInt(0); // make room for the chunk header
            children = new LinkedList<>();
        }

        public void add(Chunk child) throws IOException {
            if (children.size() > 0) {
                children.getLast().finish();
            }
            children.add(child);
        }

        /**
         * Writes the chunk and all its children to the ImageOutputStream and
         * disposes of all resources held by the chunk.
         *
         * @throws java.io.IOException when CompositeChunk is too large.
         */
        @Override
        public void finish() throws IOException {
            if (!finished) {
                if (size() > 0xffffffffL) {
                    throw new IOException("CompositeChunk \"" + chunkType + "\" is too large: " + size());
                }

                long pointer = getRelativeStreamPosition();
                seekRelative(offset);

                out.setByteOrder(ByteOrder.BIG_ENDIAN);
                out.writeInt(compositeType);
                out.setByteOrder(ByteOrder.LITTLE_ENDIAN);
                out.writeInt((int) (size() - 8));
                out.setByteOrder(ByteOrder.BIG_ENDIAN);
                out.writeInt(chunkType);
                out.setByteOrder(ByteOrder.LITTLE_ENDIAN);
                for (Chunk child : children) {
                    child.finish();
                }
                seekRelative(pointer);
                if (size() % 2 == 1) {
                    out.writeByte(0); // write pad byte
                }
                finished = true;
            }
        }

        @Override
        public long size() {
            long length = 12;
            for (Chunk child : children) {
                length += child.size() + child.size() % 2;
            }
            return length;
        }
    }

    /**
     * Data Chunk.
     */
    protected class DataChunk extends Chunk {

        protected boolean finished;
        private long finishedSize;

        /**
         * Creates a new DataChunk at the current position of the
         * ImageOutputStream.
         *
         * @param name The name of the chunk.
         */
        public DataChunk(int name) throws IOException {
            this(name, -1);
        }

        /**
         * Creates a new DataChunk at the current position of the
         * ImageOutputStream.
         *
         * @param name The name of the chunk.
         * @param dataSize The size of the chunk data, or -1 if not known.
         */
        public DataChunk(int name, long dataSize) throws IOException {
            super(name);
            out.setByteOrder(ByteOrder.BIG_ENDIAN);
            out.writeInt(chunkType);
            out.setByteOrder(ByteOrder.LITTLE_ENDIAN);
            out.writeInt((int) Math.max(0, dataSize));
            finishedSize = dataSize == -1 ? -1 : dataSize + 8;
        }

        public ImageOutputStream getOutputStream() {
            if (finished) {
                throw new IllegalStateException("DataChunk is finished");
            }
            return out;
        }

        @Override
        public void finish() throws IOException {
            if (!finished) {
                if (finishedSize == -1) {
                    finishedSize = size();

                    if (finishedSize > 0xffffffffL) {
                        throw new IOException("DataChunk \"" + chunkType + "\" is too large: " + size());
                    }

                    seekRelative(offset + 4);
                    out.writeInt((int) (finishedSize - 8));
                    seekRelative(offset + finishedSize);
                } else {
                    if (size() != finishedSize) {
                        throw new IOException("DataChunk \"" + chunkType + "\" actual size differs from given size: actual size:" + size() + " given size:" + finishedSize);
                    }
                }
                if (size() % 2 == 1) {
                    out.writeByte(0); // write pad byte
                }

                finished = true;
            }
        }

        @Override
        public long size() {
            if (finished) {
                return finishedSize;
            }

            try {
                return out.getStreamPosition() - offset;
            } catch (IOException ex) {
                InternalError ie = new InternalError("IOException");
                ie.initCause(ex);
                throw ie;
            }
        }
    }

    /**
     * A DataChunk with a fixed size.
     */
    protected class FixedSizeDataChunk extends Chunk {

        protected boolean finished;
        protected long fixedSize;

        /**
         * Creates a new DataChunk at the current position of the
         * ImageOutputStream.
         *
         * @param chunkType The chunkType of the chunk.
         */
        public FixedSizeDataChunk(int chunkType, long fixedSize) throws IOException {
            super(chunkType);
            this.fixedSize = fixedSize;
            out.setByteOrder(ByteOrder.BIG_ENDIAN);
            out.writeInt(chunkType);
            out.setByteOrder(ByteOrder.LITTLE_ENDIAN);
            out.writeInt((int) fixedSize);

            // Fill fixed size with nulls
            byte[] buf = new byte[(int) Math.min(512, fixedSize)];
            long written = 0;
            while (written < fixedSize) {
                out.write(buf, 0, (int) Math.min(buf.length, fixedSize - written));
                written += Math.min(buf.length, fixedSize - written);
            }
            if (fixedSize % 2 == 1) {
                out.writeByte(0); // write pad byte
            }
            seekToStartOfData();
        }

        public ImageOutputStream getOutputStream() {
            return out;
        }

        public void seekToStartOfData() throws IOException {
            seekRelative(offset + 8);

        }

        public void seekToEndOfChunk() throws IOException {
            seekRelative(offset + 8 + fixedSize + fixedSize % 2);
        }

        @Override
        public void finish() {
            if (!finished) {
                finished = true;
            }
        }

        @Override
        public long size() {
            return 8 + fixedSize;
        }
    }

    /**
     * Gets the position relative to the beginning of the QuickTime stream. <p>
     * Usually this value is equal to the stream position of the underlying
     * ImageOutputStream, but can be larger if the underlying stream already
     * contained data.
     *
     * @return The relative stream position.
     * @throws IOException for the ImageOutputStream
     */
    protected long getRelativeStreamPosition() throws IOException {
        return out.getStreamPosition() - streamOffset;
    }

    /**
     * Seeks relative to the beginning of the AVI stream. <p> Usually this equal
     * to seeking in the underlying ImageOutputStream, but can be different if
     * the underlying stream already contained data.
     */
    protected void seekRelative(long newPosition) throws IOException {
        out.seek(newPosition + streamOffset);
    }

    protected static int typeToInt(String str) {
        return ((str.charAt(0) & 0xff) << 24) | ((str.charAt(1) & 0xff) << 16) | ((str.charAt(2) & 0xff) << 8) | (str.charAt(3) & 0xff);
    }
}

/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.format.Format;
import java.util.ArrayList;

/**
 * {@code AbstractCodec}.
 *
 * @author Werner Randelshofer
 * @version 1.0 2011-03-12 Created.
 */
public abstract class AbstractCodec implements Codec {

    protected Format[] inputFormats;
    protected Format[] outputFormats;
    protected Format inputFormat;
    protected Format outputFormat;
    protected String name = "unnamed codec";

    public AbstractCodec(Format[] supportedInputOutputFormats) {
        this.inputFormats = supportedInputOutputFormats;
        this.outputFormats = supportedInputOutputFormats;
    }

    @Override
    public Format[] getInputFormats() {
        return inputFormats.clone();
    }

    @Override
    public Format[] getOutputFormats(Format input) {
        ArrayList<Format> of = new ArrayList<>(outputFormats.length);
        for (Format f : outputFormats) {
            of.add(input == null ? f : f.append(input));
        }
        return of.toArray(new Format[of.size()]);
    }

    @Override
    public Format setInputFormat(Format f) {
        if (f != null)
        for (Format sf : getInputFormats()) {
            if (sf.matches(f)) {
                this.inputFormat = sf.append(f);
                return inputFormat;
            }
        }
        this.inputFormat = null;
        return null;
    }

    @Override
    public Format setOutputFormat(Format f) {
        for (Format sf : getOutputFormats(f)) {
            if (sf.matches(f)) {
                this.outputFormat = f;
                return sf;
            }
        }
        this.outputFormat = null;
        return null;
    }

    @Override
    public Format getInputFormat() {
        return inputFormat;
    }

    @Override
    public Format getOutputFormat() {
        return outputFormat;
    }

    @Override
    public String getName() {
        return name;
    }

    /** Empty implementation of the reset method. Don't call super. */
    @Override
    public void reset() {
        // empty
    }

    @Override
    public String toString() {
        String className = getClass().getName();
        int p = className.lastIndexOf('.');
        return className.substring(p + 1) + "{" + "inputFormat = " + inputFormat + ", outputFormat = " + outputFormat + '}';
    }
}

/*
 * @(#)AbstractVideoCodec.java
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.format.Format;
import com.videorecorder.video.nio.Buffer;
import java.awt.Graphics2D;
import java.awt.image.BufferedImage;
import java.awt.image.DataBufferByte;
import java.awt.image.DataBufferInt;
import java.awt.image.DataBufferShort;
import java.awt.image.DataBufferUShort;
import java.awt.image.DirectColorModel;
import static com.videorecorder.video.format.VideoFormatKeys.HeightKey;
import static com.videorecorder.video.format.VideoFormatKeys.WidthKey;

/**
 * {@code AbstractVideoCodec}.
 *
 * @author Werner Randelshofer
 * @version $Id: AbstractVideoCodec.java 299 2013-01-03 07:40:18Z werner $
 */
public abstract class AbstractVideoCodec extends AbstractCodec {

    private BufferedImage imgConverter;

    public AbstractVideoCodec(Format[] supportedInputFormats) {
        super(supportedInputFormats);
    }

    /** Gets 8-bit indexed pixels from a buffer. Returns null if conversion failed. */
    protected byte[] getIndexed8(Buffer buf) {
        if (buf.data instanceof byte[]) {
            return (byte[]) buf.data;
        }
        if (buf.data instanceof BufferedImage) {
            BufferedImage image = (BufferedImage) buf.data;
            if (image.getRaster().getDataBuffer() instanceof DataBufferByte) {
                return ((DataBufferByte) image.getRaster().getDataBuffer()).getData();
            }
        }
        return null;
    }

    /** Gets 15-bit RGB pixels from a buffer. Returns null if conversion failed. */
    protected short[] getRGB15(Buffer buf) {
        if (buf.data instanceof int[]) {
            return (short[]) buf.data;
        }
        if (buf.data instanceof BufferedImage) {
            BufferedImage image = (BufferedImage) buf.data;
            if (image.getColorModel() instanceof DirectColorModel) {
                DirectColorModel dcm = (DirectColorModel) image.getColorModel();
                if (image.getRaster().getDataBuffer() instanceof DataBufferShort) {
                    // FIXME - Implement additional checks
                    return ((DataBufferShort) image.getRaster().getDataBuffer()).getData();
                } else if (image.getRaster().getDataBuffer() instanceof DataBufferUShort) {
                    // FIXME - Implement additional checks
                    return ((DataBufferUShort) image.getRaster().getDataBuffer()).getData();
                }
            }
            if (imgConverter == null) {
                int width = outputFormat.get(WidthKey);
                int height = outputFormat.get(HeightKey);
                imgConverter = new BufferedImage(width, height, BufferedImage.TYPE_USHORT_555_RGB);
            }
            Graphics2D g = imgConverter.createGraphics();
            g.drawImage(image, 0, 0, null);
            g.dispose();
            return ((DataBufferUShort) imgConverter.getRaster().getDataBuffer()).getData();
        }
        return null;
    }

    /** Gets 24-bit RGB pixels from a buffer. Returns null if conversion failed. */
    protected int[] getRGB24(Buffer buf) {
        if (buf.data instanceof int[]) {
            return (int[]) buf.data;
        }
        if (buf.data instanceof BufferedImage) {
            BufferedImage image = (BufferedImage) buf.data;
            if (image.getColorModel() instanceof DirectColorModel) {
                DirectColorModel dcm = (DirectColorModel) image.getColorModel();
                if (dcm.getBlueMask() == 0xff && dcm.getGreenMask() == 0xff00 && dcm.getRedMask() == 0xff0000) {
                    if (image.getRaster().getDataBuffer() instanceof DataBufferInt) {
                        return ((DataBufferInt) image.getRaster().getDataBuffer()).getData();
                    }
                }
            }
            return image.getRGB(0, 0, //
                    outputFormat.get(WidthKey), outputFormat.get(HeightKey), //
                    null, 0, outputFormat.get(WidthKey));
        }
        return null;
    }

    /** Gets 32-bit ARGB pixels from a buffer. Returns null if conversion failed. */
    protected int[] getARGB32(Buffer buf) {
        if (buf.data instanceof int[]) {
            return (int[]) buf.data;
        }
        if (buf.data instanceof BufferedImage) {
            BufferedImage image = (BufferedImage) buf.data;
            if (image.getColorModel() instanceof DirectColorModel) {
                DirectColorModel dcm = (DirectColorModel) image.getColorModel();
                if (dcm.getBlueMask() == 0xff && dcm.getGreenMask() == 0xff00 && dcm.getRedMask() == 0xff0000) {
                    if (image.getRaster().getDataBuffer() instanceof DataBufferInt) {
                        return ((DataBufferInt) image.getRaster().getDataBuffer()).getData();
                    }
                }
            }
            return image.getRGB(0, 0, //
                    outputFormat.get(WidthKey), outputFormat.get(HeightKey), //
                    null, 0, outputFormat.get(WidthKey));
        }
        return null;
    }
}

/*
 * @(#)AbstractVideoCodecCore.java
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.codec;

import java.io.IOException;
import javax.imageio.stream.ImageOutputStream;

/**
 * {@code AbstractVideoCodecCore}.
 *
 * @author Werner Randelshofer
 * @version $Id: AbstractVideoCodecCore.java 299 2013-01-03 07:40:18Z werner $
 */
public class AbstractVideoCodecCore {

    private byte[] byteBuf = new byte[4];

    protected void writeInt24LE(ImageOutputStream out, int v) throws IOException {
        byteBuf[0] = (byte) (v >>> 0);
        byteBuf[1] = (byte) (v >>> 8);
        byteBuf[2] = (byte) (v >>> 16);
        out.write(byteBuf, 0, 3);
    }

    protected void writeInts24LE(ImageOutputStream out, int[] i, int off, int len) throws IOException {
        if (off < 0 || len < 0 || off + len > i.length || off + len < 0) {
            throw new IndexOutOfBoundsException("off < 0 || len < 0 || off + len > i.length!");
        }

        for (int j = 0; j < len; j++) {
            writeInt24LE(out, i[off + j]);
        }
    }
}

/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.format.Format;
import com.videorecorder.video.nio.Buffer;

/**
 * A {@code Codec} processes a {@code Buffer} and stores the result in another
 * {@code Buffer}.
 *
 * @author Werner Randelshofer
 * @version 1.0 2011-03-12 Created.
 */
public interface Codec {

    /** The codec successfully converted the input to output. */
    int CODEC_OK = 0;

    /** The codec could not handle the input. */
    int CODEC_FAILED = 1;

    /** Lists all of the input formats that this codec accepts. */
    Format[] getInputFormats();

    /** Lists all of the output formats that this codec can generate
     * with the provided input format. If the input format is null, returns
     * all supported output formats.
     */
    Format[] getOutputFormats(Format input);

    /** Sets the input format.
     * Returns the format that was actually set. This is the closest format
     * that the Codec supports. Returns null if the specified format is not
     * supported and no reasonable match could be found.
     */
    Format setInputFormat(Format input);

    Format getInputFormat();

    /** Sets the output format.
     * Returns the format that was actually set. This is the closest format
     * that the Codec supports. Returns null if the specified format is not
     * supported and no reasonable match could be found.
     */
    Format setOutputFormat(Format output);

    Format getOutputFormat();

    /** Performs the media processing defined by this codec. 
     * <p>
     * Copies the data from the input buffer into the output buffer.
     * 
     * @return A combination of processing flags.
     */
    int process(Buffer in, Buffer out);

    /** Returns a human readable name of the codec. */
    String getName();

    /** Resets the state of the codec. */
    void reset();
}

/*
 * @(#)Registry.java  
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.avi.AVIWriter;
import com.videorecorder.video.format.Format;
import com.videorecorder.video.format.FormatKey;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedList;
import java.util.Map;
import static com.videorecorder.video.format.FormatKey.EncodingKey;
import static com.videorecorder.video.format.FormatKey.MIME_AVI;
import static com.videorecorder.video.format.FormatKey.MIME_JAVA;
import static com.videorecorder.video.format.FormatKey.MIME_QUICKTIME;
import static com.videorecorder.video.format.FormatKey.MediaTypeKey;
import static com.videorecorder.video.format.FormatKey.MimeTypeKey;
import static com.videorecorder.video.format.VideoFormatKeys.COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE;
import static com.videorecorder.video.format.VideoFormatKeys.CompressorNameKey;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_BUFFERED_IMAGE;

/**
 * The {@code Registry} for audio and video codecs.
 *
 * @author Werner Randelshofer
 * @version $Id: Registry.java 299 2013-01-03 07:40:18Z werner $
 */
public class Registry {

    private HashMap<String, LinkedList<RegistryEntry>> codecMap;
    private HashMap<String, LinkedList<RegistryEntry>> writerMap;

    private static class RegistryEntry {

        Format inputFormat;
        Format outputFormat;
        String className;

        public RegistryEntry(Format inputFormat, Format outputFormat, String className) {
            this.inputFormat = inputFormat;
            this.outputFormat = outputFormat;
            this.className = className;
        }
    }

    private static Registry instance;

    public static Registry getInstance() {
        if (instance == null) {
            instance = new Registry();
            instance.init();
        }
        return instance;
    }

    /**
     * Initializes the registry.
     */
    protected void init() {
        codecMap = new HashMap<>();
        writerMap = new HashMap<>();

        putBidiCodec(
            new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_AVI, EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE),
            new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_JAVA, EncodingKey, ENCODING_BUFFERED_IMAGE),
                TechSmithCodec.class.getName());

        putBidiCodec(
            new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_QUICKTIME, EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE),
            new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_JAVA, EncodingKey, ENCODING_BUFFERED_IMAGE),
                TechSmithCodec.class.getName());

        putWriter(new Format(MediaTypeKey, FormatKey.MediaType.FILE, MimeTypeKey, MIME_AVI), AVIWriter.class.getName());
    }

    /**
     *
     * @param inputFormat Must have {@code MediaTypeKey}, {@code EncodingKey}, {@code MimeTypeKey}.
     * @param outputFormat Must have {@code MediaTypeKey}, {@code EncodingKey}, {@code MimeTypeKey}.
     * @param codecClass The string codec class.
     */
    public void putBidiCodec(Format inputFormat, Format outputFormat, String codecClass) {
        putCodec(inputFormat, outputFormat, codecClass);
        putCodec(outputFormat, inputFormat, codecClass);
    }

    /**
     * Puts a codec into the registry.
     *
     * @param inputFormat The input format. Must not be null.
     * @param outputFormat The output format. Must not be null.
     * @param codecClass The codec class name. Must not be null.
     */
    public void putCodec(Format inputFormat, Format outputFormat, String codecClass) {
        RegistryEntry entry = new RegistryEntry(inputFormat, outputFormat, codecClass);
        addCodecEntry(inputFormat.get(EncodingKey), entry);
        addCodecEntry(outputFormat.get(EncodingKey), entry);
    }

    private void addCodecEntry(String key, RegistryEntry entry) {
        LinkedList<RegistryEntry> list = codecMap.get(key);
        if (list == null) {
            list = new LinkedList<>();
            codecMap.put(key, list);
        }
        list.add(entry);
    }

    /**
     * Gets all codecs which can transcode from the specified input format to
     * the specified output format.
     *
     * @param inputFormat The input format.
     * @param outputFormat The output format.
     * @return An array of codec class names. If no codec was found, an empty
     * array is returned.
     */
    public String[] getCodecClasses(Format inputFormat, Format outputFormat) {
        HashSet<String> classNames = new HashSet<>();
        HashSet<RegistryEntry> entries = new HashSet<>();
        if (inputFormat != null) {
            LinkedList<RegistryEntry> re;
            if (inputFormat.get(EncodingKey) == null) {
                re = new LinkedList<>();
                for (Map.Entry<String, LinkedList<RegistryEntry>> i : codecMap.entrySet()) {
                    for (RegistryEntry j : i.getValue()) {
                        if (inputFormat.matches(j.inputFormat)) {
                            re.add(j);
                        }
                    }
                }
            } else {
                re = codecMap.get(inputFormat.get(EncodingKey));
            }
            if (re != null) {
                entries.addAll(re);
            }
        }
        if (outputFormat != null) {
            LinkedList<RegistryEntry> re;
            if (outputFormat.get(EncodingKey) == null) {
                re = new LinkedList<>();
                for (Map.Entry<String, LinkedList<RegistryEntry>> i : codecMap.entrySet()) {
                    for (RegistryEntry j : i.getValue()) {
                        if (outputFormat.matches(j.outputFormat)) {
                            re.add(j);
                        }
                    }
                }
            } else {
                re = codecMap.get(outputFormat.get(EncodingKey));
            }
            if (re != null) {
                entries.addAll(re);
            }
        }
        for (RegistryEntry e : entries) {
            if ((inputFormat == null || e.inputFormat == null || inputFormat.matches(e.inputFormat))
                    && (outputFormat == null || e.outputFormat == null || outputFormat.matches(e.outputFormat))) {
                classNames.add(e.className);
            }
        }
        return classNames.toArray(new String[classNames.size()]);
    }

    /**
     * Gets the first codec which can encode the specified foramt.
     *
     * @param outputFormat The output format.
     * @return A codec. Returns null if no codec was found.
     */
    public Codec getEncoder(Format outputFormat) {
        return getCodec(null, outputFormat);
    }

    /**
     * Gets a codec which can transcode from the specified input format to the
     * specified output format.
     *
     * @param inputFormat The input format.
     * @param outputFormat The output format.
     * @return A codec or null.
     */
    public Codec getCodec(Format inputFormat, Format outputFormat) {
        String[] clazz = getCodecClasses(inputFormat, outputFormat);
        for (int i = 0; i < clazz.length; i++) {
            try {
                Codec codec = ((Codec) Class.forName(clazz[i]).newInstance());
                codec.setInputFormat(inputFormat);
                if (outputFormat != null) {
                    codec.setOutputFormat(outputFormat);
                }
                return codec;
            } catch (Exception ex) {
                System.err.println("Monte Registry. Codec class not found: " + clazz[i]);
                unregisterCodec(clazz[i]);
            }
        }
        return null;
    }

    /**
     * Puts a writer into the registry.
     *
     * @param fileFormat The file format, e.g."video/avi", "video/quicktime".
     * Use "Java" for formats which are not tied to a file format. Must not be
     * null.
     * @param writerClass The writer class name. Must not be null.
     */
    public void putWriter(Format fileFormat, String writerClass) {
        RegistryEntry entry = new RegistryEntry(fileFormat, null, writerClass);
        String key = fileFormat.get(MimeTypeKey);
        LinkedList<RegistryEntry> list = writerMap.get(key);
        if (list == null) {
            list = new LinkedList<>();
            writerMap.put(key, list);
        }
        list.add(entry);
    }

    public void unregisterCodec(String codecClass) {
        for (Map.Entry<String, LinkedList<RegistryEntry>> i:codecMap.entrySet()) {
            LinkedList<RegistryEntry> ll=i.getValue();
            for (Iterator<RegistryEntry> j = ll.iterator(); j.hasNext();) {
                RegistryEntry e = j.next();
                if (e.className.equals(codecClass)) {
                    j.remove();
                }
            }
        }
    }
}

/*
 * @(#)TechSmithCodec.java 
 *
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 *
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.format.Format;
import com.videorecorder.video.format.FormatKey;
import com.videorecorder.video.io.SeekableByteArrayOutputStream;
import com.videorecorder.video.nio.Buffer;
import java.awt.Rectangle;
import java.awt.image.BufferedImage;
import java.awt.image.WritableRaster;
import java.io.IOException;
import static com.videorecorder.video.format.FormatKey.EncodingKey;
import static com.videorecorder.video.format.FormatKey.FrameRateKey;
import static com.videorecorder.video.format.FormatKey.KeyFrameIntervalKey;
import static com.videorecorder.video.format.FormatKey.MIME_AVI;
import static com.videorecorder.video.format.FormatKey.MIME_QUICKTIME;
import static com.videorecorder.video.format.FormatKey.MediaTypeKey;
import static com.videorecorder.video.format.FormatKey.MimeTypeKey;
import static com.videorecorder.video.format.VideoFormatKeys.COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE;
import static com.videorecorder.video.format.VideoFormatKeys.CompressionLevelKey;
import static com.videorecorder.video.format.VideoFormatKeys.CompressorNameKey;
import static com.videorecorder.video.format.VideoFormatKeys.DataClassKey;
import static com.videorecorder.video.format.VideoFormatKeys.DepthKey;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE;
import static com.videorecorder.video.format.VideoFormatKeys.FixedFrameRateKey;
import static com.videorecorder.video.format.VideoFormatKeys.HeightKey;
import static com.videorecorder.video.format.VideoFormatKeys.WidthKey;
import static com.videorecorder.video.nio.BufferFlag.DISCARD;
import static com.videorecorder.video.nio.BufferFlag.KEYFRAME;
import static com.videorecorder.video.nio.BufferFlag.SAME_DATA;

/**
 * {@code TechSmithCodec} (tscc) encodes a BufferedImage as a byte[] array. <p>
 * The TechSmith codec works with AVI and QuickTime. <p> This codec supports
 * encoding from a {@code BufferedImage} into the file format, and decoding from
 * the file format to a {@code BufferedImage}. <p> <p> This codec does not
 * encode the color palette of an image. This must be done separately. <p>
 * Supported input formats: <ul> {@code Format} with
 * {@code BufferedImage.class}, any width, any height, depth=8,16 or 24. </ul>
 * Supported output formats: <ul> {@code Format} with {@code byte[].class}, same
 * width and height as input format, depth=8,16 or 24. </ul> The codec supports
 * lossless delta- and key-frame encoding of images with 8, 16 or 24 bits per
 * pixel. <p> Compression of a frame is performed in two steps: In the first,
 * step a frame is compressed line by line from bottom to top. In the second
 * step the resulting data is compressed again using zlib compression. <p> Apart
 * from the second compression step and the support for 16- and 24-bit data,
 * this encoder is identical to the RunLengthCodec. <p> Each line of a
 * frame is compressed individually. A line consists of two-byte op-codes
 * optionally followed by data. The end of the line is marked with the EOL
 * op-code. <p> The following op-codes are supported: <ul> <li>{@code 0x00 0x00}
 * <br>Marks the end of a line.</li>
 *
 * <li>{@code  0x00 0x01} <br>Marks the end of the bitmap.</li>
 *
 * <li>{@code 0x00 0x02 x y} <br> Marks a delta (skip). {@code x} and {@code y}
 * indicate the horizontal and vertical offset from the current position.
 * {@code x} and {@code y} are unsigned 8-bit values.</li>
 *
 * <li>{@code 0x00 n pixel{n} 0x00?} <br> Marks a literal run. {@code n} gives
 * the number of 8-, 16- or 24-bit pixels that follow. {@code n} must be between
 * 3 and 255. If n is odd and 8-bit pixels are used, a pad byte with the value
 * 0x00 must be added. </li> <li>{@code n pixel} <br> Marks a repetition.
 * {@code n} gives the number of times the given pixel is repeated. {@code n}
 * must be between 1 and 255. </li> </ul> Example:
 * <pre>
 * Compressed data         Expanded data
 *
 * 03 04                   04 04 04
 * 05 06                   06 06 06 06 06
 * 00 03 45 56 67 00       45 56 67
 * 02 78                   78 78
 * 00 02 05 01             Move 5 right and 1 down
 * 02 78                   78 78
 * 00 00                   End of line
 * 09 1E                   1E 1E 1E 1E 1E 1E 1E 1E 1E
 * 00 01                   End of RLE bitmap
 * </pre>
 *
 * References:<br/> <a
 * href="http://wiki.multimedia.cx/index.php?title=TechSmith_Screen_Capture_Codec"
 * >http://wiki.multimedia.cx/index.php?title=TechSmith_Screen_Capture_Codec</a><br>
 *
 *
 * @author Werner Randelshofer
 * @version $Id: TechSmithCodec.java 299 2013-01-03 07:40:18Z werner $
 */
public class TechSmithCodec extends AbstractVideoCodec {

    public static final Integer DEFAULT_COMPRESSION_LEVEL = 6;

    private TechSmithCodecCore state;
    private Object previousPixels;
    private int frameCounter;

    public TechSmithCodec() {
        super(
            new Format[] {
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_AVI,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 8),
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_AVI,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 16),
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_AVI,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 24),
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_QUICKTIME,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 8),
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_QUICKTIME,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 16),
                new Format(MediaTypeKey, FormatKey.MediaType.VIDEO, MimeTypeKey, MIME_QUICKTIME,
                    EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
                    CompressorNameKey, COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
                    DataClassKey, byte[].class,
                    FixedFrameRateKey, true, DepthKey, 24),
            });
        name = COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE;
    }

    @Override
    public void reset() {
        state = null;
        frameCounter = 0;
    }

    @Override
    public int process(Buffer in, Buffer out) {
        if (state == null) {
            state = new TechSmithCodecCore();
        }
        if (in.isFlag(DISCARD)) {
            out.setMetaTo(in);
            return CODEC_OK;
        }
        
        if (outputFormat.get(EncodingKey).equals(ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE)) {
            return encode(in, out);
        } else {
            return CODEC_OK;
        }
    }

    public int encode(Buffer in, Buffer out) {
        out.setMetaTo(in);
        out.format = outputFormat;
        if (in.isFlag(DISCARD)) {
            return CODEC_OK;
        }

        SeekableByteArrayOutputStream tmp;
        if (out.data instanceof byte[]) {
            tmp = new SeekableByteArrayOutputStream((byte[]) out.data);
        } else {
            tmp = new SeekableByteArrayOutputStream();
        }

        boolean isKeyframe = frameCounter == 0 ||
            frameCounter % outputFormat.get(KeyFrameIntervalKey, outputFormat.get(FrameRateKey)) == 0;
        out.setFlag(KEYFRAME, isKeyframe);
        out.clearFlag(SAME_DATA);
        frameCounter++;

        // Handle sub-image
        Rectangle r;
        int scanlineStride;
        if (in.data instanceof BufferedImage) {
            BufferedImage image = (BufferedImage) in.data;
            WritableRaster raster = image.getRaster();
            scanlineStride = raster.getSampleModel().getWidth();
            r = raster.getBounds();
            r.x -= raster.getSampleModelTranslateX();
            r.y -= raster.getSampleModelTranslateY();
            out.header = image.getColorModel();
        } else {
            r = new Rectangle(0, 0, outputFormat.get(WidthKey), outputFormat.get(HeightKey));
            scanlineStride = outputFormat.get(WidthKey);
            out.header = null;
        }
        int offset = r.x + r.y * scanlineStride;

        try {
            switch (outputFormat.get(DepthKey)) {
                case 8: {
                    byte[] pixels = getIndexed8(in);
                    if (pixels == null) {
                        out.setFlag(DISCARD);
                        return CODEC_OK;
                    }

                    if (isKeyframe) {
                        state.encodeKey8(tmp, pixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                            offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                    } else {
                        if (in.isFlag(SAME_DATA)) {
                            state.encodeSameDelta8(tmp);
                        } else {
                            state.encodeDelta8(tmp, pixels, (byte[]) previousPixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                                offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                        }
                        out.clearFlag(KEYFRAME);
                    }
                    if (previousPixels == null) {
                        previousPixels = pixels.clone();
                    } else {
                        System.arraycopy(pixels, 0, (byte[]) previousPixels, 0, pixels.length);
                    }
                    break;
                }
                case 16: {
                    short[] pixels = getRGB15(in); // 16-bit TSCC is actually just 15-bit
                    if (pixels == null) {
                        out.setFlag(DISCARD);
                        return CODEC_OK;
                    }

                    if (isKeyframe) {
                        state.encodeKey16(tmp, pixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                            offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                    } else {
                        if (in.isFlag(SAME_DATA)) {
                            state.encodeSameDelta16(tmp);
                        } else {
                            state.encodeDelta16(tmp, pixels, (short[]) previousPixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                                offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                        }
                    }
                    if (previousPixels == null) {
                        previousPixels = pixels.clone();
                    } else {
                        System.arraycopy(pixels, 0, (short[]) previousPixels, 0, pixels.length);
                    }
                    break;
                }
                case 24: {
                    int[] pixels = getRGB24(in);
                    if (pixels == null) {
                        out.setFlag(DISCARD);
                        return CODEC_OK;
                    }

                    if (isKeyframe) {
                        state.encodeKey24(tmp, pixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                            offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                        out.setFlag(KEYFRAME);
                    } else {
                        if (in.isFlag(SAME_DATA)) {
                            state.encodeSameDelta24(tmp);
                        } else {
                            state.encodeDelta24(tmp, pixels, (int[]) previousPixels, outputFormat.get(WidthKey), outputFormat.get(HeightKey),
                                offset, scanlineStride, outputFormat.get(CompressionLevelKey, DEFAULT_COMPRESSION_LEVEL));
                        }
                        out.clearFlag(KEYFRAME);
                    }
                    if (previousPixels == null) {
                        previousPixels = pixels.clone();
                    } else {
                        System.arraycopy(pixels, 0, (int[]) previousPixels, 0, pixels.length);
                    }
                    break;
                }
                default: {
                    out.setFlag(DISCARD);
                    return CODEC_FAILED;
                }
            }

            out.format = outputFormat;
            out.data = tmp.getBuffer();
            out.offset = 0;
            out.sampleCount = 1;
            out.length = tmp.size();
            return CODEC_OK;
        } catch (IOException ex) {
            ex.printStackTrace();
            out.setFlag(DISCARD);
            return CODEC_OK;
        }
    }
}

/*
 * @(#)TechSmithCodecCore.java 
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.codec;

import com.videorecorder.video.io.ByteArrayImageOutputStream;
import java.io.IOException;
import java.io.OutputStream;
import java.nio.ByteOrder;
import java.util.zip.Deflater;
import java.util.zip.DeflaterOutputStream;

/**
 * {@code TechSmithCodec} (tscc) encodes a BufferedImage as a byte[] array.
 * <p>
 * This codec does not encode the color palette of an image. This must be done
 * separately.
 * <p>
 * Supported input formats:
 * <ul>
 * {@code Format} with {@code BufferedImage.class}, any width, any height,
 * depth=8,16 or 24.
 * </ul>
 * Supported output formats:
 * <ul>
 * {@code Format} with {@code byte[].class}, same width and height as input
 * format, depth=8,16 or 24.
 * </ul>
 * The codec supports lossless delta- and key-frame encoding of images with 8, 16 or
 * 24 bits per pixel.
 * <p>
 * Compression of a frame is performed in two steps: In the first, step
 * a frame is compressed line by line from bottom to top. In the second step
 * the resulting data is compressed again using zlib compression.
 * <p>
 * Apart from the second compression step and the support for 16- and 24-bit
 * data, this encoder is identical to the RunLengthCodec.
 * <p>
 * Each line of a frame is compressed individually. A line consists of two-byte
 * op-codes optionally followed by data. The end of the line is marked with
 * the EOL op-code.
 * <p>
 * The following op-codes are supported:
 * <ul>
 * <li>{@code 0x00 0x00}
 * <br>Marks the end of a line.</li>
 *
 * <li>{@code  0x00 0x01}
 * <br>Marks the end of the bitmap.</li>
 *
 * <li>{@code 0x00 0x02 dx dy}
 * <br> Marks a delta (skip). {@code dx} and {@code dy}
 * indicate the horizontal and vertical offset from the current position.
 * {@code dx} and {@code dy} are unsigned 8-bit values.</li>
 *
 * <li>{@code 0x00 n pixel{n} 0x00?}
 * <br> Marks a literal run. {@code n}
 * gives the number of 8-, 16- or 24-bit pixels that follow.
 * {@code n} must be between 3 and 255.
 * If n is odd and 8-bit pixels are used, a pad byte with the value 0x00 must be
 * added.
 * </li>
 * <li>{@code n pixel}
 * <br> Marks a repetition. {@code n}
 * gives the number of times the given pixel is repeated. {@code n} must be
 * between 1 and 255.
 * </li>
 * </ul>
 * Example:
 * <pre>
 * Compressed data         Expanded data
 *
 * 03 04                   04 04 04
 * 05 06                   06 06 06 06 06
 * 00 03 45 56 67 00       45 56 67
 * 02 78                   78 78
 * 00 02 05 01             Move 5 right and 1 down
 * 02 78                   78 78
 * 00 00                   End of line
 * 09 1E                   1E 1E 1E 1E 1E 1E 1E 1E 1E
 * 00 01                   End of RLE bitmap
 * </pre>
 *
 * References:<br/>
 * <a href="http://wiki.multimedia.cx/index.php?title=TechSmith_Screen_Capture_Codec"
 * >http://wiki.multimedia.cx/index.php?title=TechSmith_Screen_Capture_Codec</a><br>
 *
 * <p><b>Palette colors</b></p>
 * <p>In an AVI file, palette changes are stored in chunks with id's with the
 * suffix "pc". "pc" chunks contain an AVIPALCHANGE struct as shown below.
 * </p>
 * <pre>
 * /* ------------------
 *  * AVI Palette Change
 *  * ------------------
 *  * /
 * 
 * // Values for this enum have been taken from:
 * // http://biodi.sdsc.edu/Doc/GARP/garp-1.1/define.h
 * enum {
 *     PC_EXPLICIT = 0x02,
 *     // Specifies that the low-order word of the logical palette entry 
 *     // designates a hardware palette index. This flag allows the application to 
 *     // show the contents of the display device palette.
 *     PC_NOCOLLAPSE = 0x04,
 *     // Specifies that the color be placed in an unused entry in the system 
 *     // palette instead of being matched to an existing color in the system 
 *     // palette. If there are no unused entries in the system palette, the color 
 *     // is matched normally. Once this color is in the system palette, colors in
 *     // other logical palettes can be matched to this color.
 *     PC_RESERVED = 0x01
 *     // Specifies that the logical palette entry be used for palette animation. 
 *     // This flag prevents other windows from matching colors to the palette 
 *     // entry since the color frequently changes. If an unused system-palette
 *     // entry is available, the color is placed in that entry. Otherwise, the 
 *     // color is not available for animation.
 * } peFlagsEnum;
 * /* 
 *  * The PALETTEENTRY structure specifies the color and usage of an entry in a
 *  * logical palette. A logical palette is defined by a LOGPALETTE structure.
 *  * /
 * typedef struct { 
 *   BYTE peRed; // Specifies a red intensity value for the palette entry.
 *   BYTE peGreen; // Specifies a green intensity value for the palette entry.
 *   BYTE peBlue; // Specifies a blue intensity value for the palette entry.
 *   BYTE enum peFlagsEnum peFlags; // Specifies how the palette entry is to be used.
 * } PALETTEENTRY;
 * 
 * typedef struct {
 *   AVIPALCHANGE avipalchange;
 * } AVIPALCHANGE0;
 * 
 * typedef struct {
 *     PALETTEENTRY  p[256];
 * } PALETTEENTRY_ALLENTRIES;
 * 
 * typedef struct {
 *     BYTE          firstEntry;
 *         // Specifies the index of the first palette entry to change.
 *     BYTE          numEntries;
 *         // Specifies the number of palette entries to change, or zero to change 
 *         // all 256 palette entries.
 *     WORD          flags;
 *         // Reserved.
 *     PALETTEENTRY  peNew[numEntries];
 *         // Specifies an array of PALETTEENTRY structures, of size "numEntries".
 *     PALETTEENTRY_ALLENTRIES  all[numEntries==0];
 * } AVIPALCHANGE;
 * </pre>
 * 
 *
 * @author Werner Randelshofer
 * @version $Id: TechSmithCodecCore.java 299 2013-01-03 07:40:18Z werner $
 */
public class TechSmithCodecCore extends AbstractVideoCodecCore {

    private ByteArrayImageOutputStream temp = new ByteArrayImageOutputStream(ByteOrder.LITTLE_ENDIAN);
    private int[] palette;

    public TechSmithCodecCore() {
        reset();
    }

    public void reset() {
        palette = null;
    }

    /** Encodes an 8-bit delta frame with indexed colors.
     *
     * @param out The output stream. 
     * @param data The image data.
     * @param prev The image data of the previous frame.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeDelta8(OutputStream out, byte[] data, byte[] prev, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {

        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);

        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline
        int verticalOffset = 0;
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            // determine skip count
            int skipCount = 0;
            for (; xy < xymax; ++xy, ++skipCount) {
                if (data[xy] != prev[xy]) {
                    break;
                }
            }
            if (skipCount == width) {
                // => the entire line can be skipped
                ++verticalOffset;
                continue;
            }


            while (verticalOffset > 0 || skipCount > 0) {
                temp.write(0x00); // Escape code
                temp.write(0x02); // Skip OP-code
                temp.write(Math.min(255, skipCount)); // horizontal offset
                temp.write(Math.min(255, verticalOffset)); // vertical offset
                skipCount -= Math.min(255, skipCount);
                verticalOffset -= Math.min(255, verticalOffset);
            }

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine skip count
                for (skipCount = 0; xy < xymax; ++xy, ++skipCount) {
                    if (data[xy] != prev[xy]) {
                        break;
                    }
                }
                xy -= skipCount;

                // determine repeat count
                byte v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;

                if (skipCount < 4 && xy + skipCount < xymax && repeatCount < 3) {
                    literalCount++;
                } else {
                    while (literalCount > 0) {
                        if (literalCount < 3) {
                            temp.write(1); // Repeat OP-code
                            temp.write(data[xy - literalCount]);
                            literalCount--;
                        } else {
                            int literalRun = Math.min(254, literalCount);
                            temp.write(0); // Escape code
                            temp.write(literalRun); // Literal OP-code
                            temp.write(data, xy - literalCount, literalRun);
                            if ((literalRun & 1) == 1) {
                                temp.write(0); // pad byte
                            }
                            literalCount -= literalRun;
                        }
                    }
                    if (xy + skipCount == xymax) {
                        // => we can skip until the end of the line without
                        //    having to write an op-code
                        xy += skipCount - 1;
                    } else if (skipCount >= repeatCount) {
                        while (skipCount > 0) {
                            temp.write(0); // Escape code
                            temp.write(0x0002); // Skip OP-code
                            temp.write(Math.min(255, skipCount));
                            temp.write(0);
                            xy += Math.min(255, skipCount);
                            skipCount -= Math.min(255, skipCount);
                        }
                        xy -= 1;
                    } else {
                        temp.write(repeatCount); // Repeat OP-code
                        temp.write(v);
                        xy += repeatCount - 1;
                    }
                }
            }

            // flush literal run
            while (literalCount > 0) {
                if (literalCount < 3) {
                    temp.write(1); // Repeat OP-code
                    temp.write(data[xy - literalCount]);
                    literalCount--;
                } else {
                    int literalRun = Math.min(254, literalCount);
                    temp.write(0);
                    temp.write(literalRun); // Literal OP-code
                    temp.write(data, xy - literalCount, literalRun);
                    if ((literalRun & 1) == 1) {
                        temp.write(0); // pad byte
                    }
                    literalCount -= literalRun;
                }
            }

            temp.write(0); // Escape code
            temp.write(0x00); // End of line OP-code
        }
        temp.write(0); // Escape code
        temp.write(0x01);// End of bitmap


        if (temp.length() == 2) {
            temp.toOutputStream(out);
        } else {
            DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
            temp.toOutputStream(defl);
            defl.finish();
        }
    }

    /** Encodes a delta frame which is known to have the same content than
     * the previous frame.
     * 
     * @param out The output stream.
     * @throws IOException  for the output stream
     */
    public void encodeSameDelta8(OutputStream out) throws IOException {
        out.write(0); // Escape code
        out.write(0x01);// End of bitmap
    }

    /** Encodes a delta frame which is known to have the same content than
     * the previous frame.
     * 
     * @param out The output stream.
     * @throws IOException for the output stream
     */
    public void encodeSameDelta24(OutputStream out)
            throws IOException {
        out.write(0); // Escape code
        out.write(0x01);// End of bitmap
    }

    /** Encodes a delta frame which is known to have the same content than
     * the previous frame.
     * 
     * @param out The output stream.
     * @throws IOException for the output stream
     */
    public void encodeSameDelta16(OutputStream out) throws IOException {
        out.write(0); // Escape code
        out.write(0x01);// End of bitmap
    }

    /** Encodes a 8-bit key frame with indexed colors.
     *
     * @param out The output stream.
     * @param data The image data.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeKey8(OutputStream out, byte[] data, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {
        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);
        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline separately
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine repeat count
                byte v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;
                if (repeatCount < 3) {
                    literalCount++;
                    if (literalCount == 254) {
                        temp.write(0);
                        temp.write(literalCount); // Literal OP-code
                        temp.write(data, xy - literalCount + 1, literalCount);
                        literalCount = 0;
                    }
                } else {
                    if (literalCount > 0) {
                        if (literalCount < 3) {
                            for (; literalCount > 0; --literalCount) {
                                temp.write(1); // Repeat OP-code
                                temp.write(data[xy - literalCount]);
                            }
                        } else {
                            temp.write(0);
                            temp.write(literalCount); // Literal OP-code
                            temp.write(data, xy - literalCount, literalCount);
                            if ((literalCount & 1) == 1) {
                                temp.write(0); // pad byte
                            }
                            literalCount = 0;
                        }
                    }
                    temp.write(repeatCount); // Repeat OP-code
                    temp.write(v);
                    xy += repeatCount - 1;
                }
            }

            // flush literal run
            if (literalCount > 0) {
                if (literalCount < 3) {
                    for (; literalCount > 0; --literalCount) {
                        temp.write(1); // Repeat OP-code
                        temp.write(data[xy - literalCount]);
                    }
                } else {
                    temp.write(0);
                    temp.write(literalCount);
                    temp.write(data, xy - literalCount, literalCount);
                    if ((literalCount & 1) == 1) {
                        temp.write(0); // pad byte
                    }
                }
                literalCount = 0;
            }

            temp.write(0);
            temp.write(0x0000);// End of line
        }
        temp.write(0);
        temp.write(0x0001);// End of bitmap

        DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
        temp.toOutputStream(defl);
        defl.finish();
    }

    /** Encodes a 16-bit delta frame.
     *
     * @param out The output stream. 
     * @param data The image data.
     * @param prev The image data of the previous frame.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeDelta16(OutputStream out, short[] data, short[] prev, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {
        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);

        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline
        int verticalOffset = 0;
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            // determine skip count
            int skipCount = 0;
            for (; xy < xymax; ++xy, ++skipCount) {
                if (data[xy] != prev[xy]) {
                    break;
                }
            }
            if (skipCount == width) {
                // => the entire line can be skipped
                ++verticalOffset;
                continue;
            }

            while (verticalOffset > 0 || skipCount > 0) {
                temp.write(0x00); // Escape code
                temp.write(0x02); // Skip OP-code
                temp.write(Math.min(255, skipCount)); // horizontal offset
                temp.write(Math.min(255, verticalOffset)); // vertical offset
                skipCount -= Math.min(255, skipCount);
                verticalOffset -= Math.min(255, verticalOffset);
            }

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine skip count
                for (skipCount = 0; xy < xymax; ++xy, ++skipCount) {
                    if (data[xy] != prev[xy]) {
                        break;
                    }
                }
                xy -= skipCount;

                // determine repeat count
                short v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;

                if (skipCount < 4 && xy + skipCount < xymax && repeatCount < 3) {
                    literalCount++;
                } else {
                    while (literalCount > 0) {
                        if (literalCount < 3) {
                            temp.write(1); // Repeat OP-code
                            temp.writeShort(data[xy - literalCount]);
                            literalCount--;
                        } else {
                            int literalRun = Math.min(254, literalCount);
                            temp.write(0); // Escape code
                            temp.write(literalRun); // Literal OP-code
                            temp.writeShorts(data, xy - literalCount, literalRun);
                            literalCount -= literalRun;
                        }
                    }
                    if (xy + skipCount == xymax) {
                        // => we can skip until the end of the line without
                        //    having to write an op-code
                        xy += skipCount - 1;
                    } else if (skipCount >= repeatCount) {
                        while (skipCount > 0) {
                            temp.write(0); // Escape code
                            temp.write(0x02); // Skip OP-code
                            temp.write(Math.min(255, skipCount)); // horizontal skip
                            temp.write(0); // vertical skip
                            xy += Math.min(255, skipCount);
                            skipCount -= Math.min(255, skipCount);
                        }
                        xy -= 1;
                    } else {
                        temp.write(repeatCount); // Repeat OP-code
                        temp.writeShort(v);
                        xy += repeatCount - 1;
                    }
                }
            }

            // flush literal run
            while (literalCount > 0) {
                if (literalCount < 3) {
                    temp.write(1); // Repeat OP-code
                    temp.writeShort(data[xy - literalCount]);
                    literalCount--;
                } else {
                    int literalRun = Math.min(254, literalCount);
                    temp.write(0); // Escape code
                    temp.write(literalRun); // Literal OP-code
                    temp.writeShorts(data, xy - literalCount, literalRun);
                    literalCount -= literalRun;
                }
            }

            temp.write(0); // Escape code
            temp.write(0x00); // End of line OP-code
        }

        temp.write(0); // Escape code
        temp.write(0x01);// End of bitmap OP-code

        if (temp.length() == 2) {
            temp.toOutputStream(out);
        } else {
            DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
            temp.toOutputStream(defl);
            defl.finish();
        }
    }

    /** Encodes a 24-bit key frame.
     *
     * @param out The output stream.
     * @param data The image data.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeKey24(OutputStream out, int[] data, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {
        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);
        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline separately
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine repeat count
                int v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;
                if (repeatCount < 3) {
                    literalCount++;
                    if (literalCount == 254) {
                        temp.write(0);
                        temp.write(literalCount); // Literal OP-code
                        writeInts24LE(temp, data, xy - literalCount + 1, literalCount);
                        literalCount = 0;
                    }
                } else {
                    if (literalCount > 0) {
                        if (literalCount < 3) {
                            for (; literalCount > 0; --literalCount) {
                                temp.write(1); // Repeat OP-code
                                writeInt24LE(temp, data[xy - literalCount]);
                            }
                        } else {
                            temp.write(0);
                            temp.write(literalCount); // Literal OP-code
                            writeInts24LE(temp, data, xy - literalCount, literalCount);
                            ///if (literalCount & 1 == 1) {
                            ///    temp.write(0); // pad byte
                            ///}
                            literalCount = 0;
                        }
                    }
                    temp.write(repeatCount); // Repeat OP-code
                    writeInt24LE(temp, v);
                    xy += repeatCount - 1;
                }
            }

            // flush literal run
            if (literalCount > 0) {
                if (literalCount < 3) {
                    for (; literalCount > 0; --literalCount) {
                        temp.write(1); // Repeat OP-code
                        writeInt24LE(temp, data[xy - literalCount]);
                    }
                } else {
                    temp.write(0);
                    temp.write(literalCount);
                    writeInts24LE(temp, data, xy - literalCount, literalCount);
                    ///if (literalCount & 1 == 1) {
                    ///    temp.write(0); // pad byte
                    ///}
                }
                literalCount = 0;
            }

            temp.write(0);
            temp.write(0x0000);// End of line
        }
        temp.write(0);
        temp.write(0x0001);// End of bitmap

        DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
        temp.toOutputStream(defl);
        defl.finish();
    }

    /** Encodes a 24-bit delta frame.
     *
     * @param out The output stream. 
     * @param data The image data.
     * @param prev The image data of the previous frame.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeDelta24(OutputStream out, int[] data, int[] prev, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {

        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);

        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline
        int verticalOffset = 0;
        ScanlineLoop:
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            // determine skip count
            int skipCount = 0;
            for (; xy < xymax; ++xy, ++skipCount) {
                if (data[xy] != prev[xy]) {
                    break;
                }
            }
            if (skipCount == width) {
                // => the entire line can be skipped
                ++verticalOffset;
                continue;
            }

            while (verticalOffset > 0 || skipCount > 0) {
                temp.write(0x00); // Escape code
                temp.write(0x02); // Skip OP-code
                temp.write(Math.min(255, skipCount)); // horizontal offset
                temp.write(Math.min(255, verticalOffset)); // vertical offset
                skipCount -= Math.min(255, skipCount);
                verticalOffset -= Math.min(255, verticalOffset);
            }

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine skip count
                for (skipCount = 0; xy < xymax; ++xy, ++skipCount) {
                    if (data[xy] != prev[xy]) {
                        break;
                    }
                }
                xy -= skipCount;

                // determine repeat count
                int v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;

                if (skipCount < 4 && xy + skipCount < xymax && repeatCount < 3) {
                    literalCount++;
                } else {
                    while (literalCount > 0) {
                        if (literalCount < 3) {
                            temp.write(1); // Repeat OP-code
                            writeInt24LE(temp, data[xy - literalCount]);
                            literalCount--;
                        } else {
                            int literalRun = Math.min(254, literalCount);
                            temp.write(0);
                            temp.write(literalRun); // Literal OP-code
                            writeInts24LE(temp, data, xy - literalCount, literalRun);
                            ///if (literalRun & 1 == 1) {
                            ///    temp.write(0); // pad byte
                            ///}
                            literalCount -= literalRun;
                        }
                    }
                    if (xy + skipCount == xymax) {
                        // => we can skip until the end of the line without
                        //    having to write an op-code
                        xy += skipCount - 1;
                    } else if (skipCount >= repeatCount) {
                        while (skipCount > 0) {
                            temp.write(0);
                            temp.write(0x0002); // Skip OP-code
                            temp.write(Math.min(255, skipCount));
                            temp.write(0);
                            xy += Math.min(255, skipCount);
                            skipCount -= Math.min(255, skipCount);
                        }
                        xy -= 1;
                    } else {
                        temp.write(repeatCount); // Repeat OP-code
                        writeInt24LE(temp, v);
                        xy += repeatCount - 1;
                    }
                }
            }

            // flush literal run
            while (literalCount > 0) {
                if (literalCount < 3) {
                    temp.write(1); // Repeat OP-code
                    writeInt24LE(temp, data[xy - literalCount]);
                    literalCount--;
                } else {
                    int literalRun = Math.min(254, literalCount);
                    temp.write(0);
                    temp.write(literalRun); // Literal OP-code
                    writeInts24LE(temp, data, xy - literalCount, literalRun);
                    ///if (literalRun & 1 == 1) {
                    ///   temp.write(0); // pad byte
                    ///}
                    literalCount -= literalRun;
                }
            }

            temp.write(0); // Escape code
            temp.write(0x00); // End of line OP-code
        }

        temp.write(0); // Escape code
        temp.write(0x01);// End of bitmap

        if (temp.length() == 2) {
            temp.toOutputStream(out);
        } else {
            DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
            temp.toOutputStream(defl);
            defl.finish();
        }
    }

    /** Encodes a 16-bit key frame.
     *
     * @param out The output stream.
     * @param data The image data.
     * @param offset The offset to the first pixel in the data array.
     * @param width The width of the image in data elements.
     * @param scanlineStride The number to add to offset to get to the next scanline.
     */
    public void encodeKey16(OutputStream out, short[] data, int width, int height, int offset, int scanlineStride, int compressionLevel)
            throws IOException {
        temp.clear();temp.setByteOrder(ByteOrder.LITTLE_ENDIAN);
        int ymax = offset + height * scanlineStride;
        int upsideDown = ymax - scanlineStride + offset;

        // Encode each scanline separately
        for (int y = offset; y < ymax; y += scanlineStride) {
            int xy = upsideDown - y;
            int xymax = xy + width;

            int literalCount = 0;
            int repeatCount = 0;
            for (; xy < xymax; ++xy) {
                // determine repeat count
                short v = data[xy];
                for (repeatCount = 0; xy < xymax && repeatCount < 255; ++xy, ++repeatCount) {
                    if (data[xy] != v) {
                        break;
                    }
                }
                xy -= repeatCount;
                if (repeatCount < 3) {
                    literalCount++;
                    if (literalCount == 254) {
                        temp.write(0); // Escape code
                        temp.write(literalCount); // Literal OP-code
                        temp.writeShorts(data, xy - literalCount + 1, literalCount);
                        literalCount = 0;
                    }
                } else {
                    if (literalCount > 0) {
                        if (literalCount < 3) {
                            for (; literalCount > 0; --literalCount) {
                                temp.write(1); // Repeat OP-code
                                temp.writeShort(data[xy - literalCount]);
                            }
                        } else {
                            temp.write(0);
                            temp.write(literalCount); // Literal OP-code
                            temp.writeShorts(data, xy - literalCount, literalCount);
                            ///if (literalCount & 1 == 1) {
                            ///    temp.write(0); // pad byte
                            ///}
                            literalCount = 0;
                        }
                    }
                    temp.write(repeatCount); // Repeat OP-code
                    temp.writeShort(v);
                    xy += repeatCount - 1;
                }
            }

            // flush literal run
            if (literalCount > 0) {
                if (literalCount < 3) {
                    for (; literalCount > 0; --literalCount) {
                        temp.write(1); // Repeat OP-code
                        temp.writeShort(data[xy - literalCount]);
                    }
                } else {
                    temp.write(0);
                    temp.write(literalCount);
                    temp.writeShorts(data, xy - literalCount, literalCount);
                    ///if (literalCount & 1 == 1) {
                    ///    temp.write(0); // pad byte
                    ///}
                }
                literalCount = 0;
            }

            temp.write(0);
            temp.write(0x0000);// End of line
        }
        temp.write(0);
        temp.write(0x0001);// End of bitmap

        DeflaterOutputStream defl = new DeflaterOutputStream(out, new Deflater(compressionLevel));
        temp.toOutputStream(defl);
        defl.finish();
    }
}

/*
 * @(#)Format.java  
 * 
 * Copyright (c) 2011-2012 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance onlyWith the
 * license agreement you entered into onlyWith Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.format;

import java.util.HashMap;
import java.util.Map;

/**
 * Specifies the format of a media, for example of audio and video.
 *
 * @author Werner Randelshofer
 * @version $Id: Format.java 299 2013-01-03 07:40:18Z werner $
 */
public class Format {

    /**
     * Holds the properties of the format.
     */
    private HashMap<FormatKey, Object> properties;

    /**
     * Creates a new format onlyWith the specified properties.
     */
    public Format(Map<FormatKey, Object> properties) {
        this(properties, true);
    }

    /**
     * Creates a new format onlyWith the specified properties.
     */
    private Format(Map<FormatKey, Object> properties, boolean copy) {
        if (copy || ! (properties instanceof HashMap)) {
            for (Map.Entry<FormatKey, Object> e : properties.entrySet()) {
                if (!e.getKey().isAssignable(e.getValue())) {
                    throw new ClassCastException(e.getValue() + " must be of type " + e.getKey().getValueClass());
                }
            }
            this.properties = new HashMap<>(properties);
        } else {
            this.properties = (HashMap<FormatKey, Object>) properties;
        }
    }

    /**
     * Creates a new format onlyWith the specified properties. The properties
     * must be given as key value pairs.
     */
    public Format(Object... p) {
        this.properties = new HashMap<>();
        for (int i = 0; i < p.length; i += 2) {
            FormatKey key = (FormatKey) p[i];
            if (!key.isAssignable(p[i + 1])) {
                throw new ClassCastException(key + ": " + p[i + 1] + " must be of type " + key.getValueClass());
            }
            this.properties.put(key, p[i + 1]);
        }
    }

    @SuppressWarnings("unchecked")
    public <T> T get(FormatKey<T> key) {
        return (T) properties.get(key);
    }

    @SuppressWarnings("unchecked")
    public <T> T get(FormatKey<T> key, T defaultValue) {
        return (properties.containsKey(key)) ? (T) properties.get(key) : defaultValue;
    }

    public boolean containsKey(FormatKey key) {
        return properties.containsKey(key);
    }

    /**
     * Returns true if that format matches this format. That is iff all
     * properties defined in both format objects are identical. Properties which
     * are only defined in one of the format objects are not considered.
     *
     * @param that Another format.
     * @return True if the other format matches this format.
     */
    public boolean matches(Format that) {
        for (Map.Entry<FormatKey, Object> e : properties.entrySet()) {
            if (!e.getKey().isComment()) {
                if (that.properties.containsKey(e.getKey())) {
                    Object a = e.getValue();
                    Object b = that.properties.get(e.getKey());
                    if (a != b && a == null || !a.equals(b)) {
                        return false;
                    }

                }
            }
        }
        return true;
    }

    /**
     * Creates a new format which contains all properties from this format and
     * additional properties from that format. <p> If a property is specified in
     * both formats, then the property value from this format is used. It
     * overwrites that format. <p> If one of the format has more properties than
     * the other, then the new format is more specific than this format.
     *
     * @param that The format to be appended.
     * @return That format with properties overwritten by this format.
     */
    public Format append(Format that) {
        HashMap<FormatKey, Object> m = new HashMap<>(this.properties);
        for (Map.Entry<FormatKey, Object> e : that.properties.entrySet()) {
            if (!m.containsKey(e.getKey())) {
                m.put(e.getKey(), e.getValue());
            }
        }
        return new Format(m, false);
    }

    /**
     * Creates a new format which contains all specified properties and 
     * additional properties from this format. 
     * <p> If a property is specified in both formats, then the property value
     * from this format is used. It overwrites that format. 
     * <p> If one of the format has more properties than the other, then the new
     * format is more specific than this format.
     *
     * @param p The properties must be given as key value pairs.
     * @return That format with properties overwritten by this format.
     */
    public Format prepend(Object... p) {
        HashMap<FormatKey, Object> m = new HashMap<>();
        for (int i = 0; i < p.length; i += 2) {
            FormatKey key = (FormatKey) p[i];
            if (!key.isAssignable(p[i + 1])) {
                throw new ClassCastException(key + ": " + p[i + 1] + " must be of type " + key.getValueClass());
            }
            m.put(key, p[i + 1]);
        }
        for (Map.Entry<FormatKey, Object> e : this.properties.entrySet()) {
            if (!m.containsKey(e.getKey())) {
                m.put(e.getKey(), e.getValue());
            }
        }
        return new Format(m, false);
    }

    @Override
    public String toString() {
        StringBuilder buf = new StringBuilder("Format{");
        boolean isFirst = true;
        for (Map.Entry<FormatKey, Object> e : properties.entrySet()) {
            if (isFirst) {
                isFirst = false;
            } else {
                buf.append(',');
            }
            buf.append(e.getKey().toString());
            buf.append(':');
            appendStuffedString(e.getValue(), buf);
        }
        buf.append('}');
        return buf.toString();
    }

    /**
     * This method is used by #toString.
     */
    private static void appendStuffedString(Object value, StringBuilder stuffed) {
        if (value == null) {
            stuffed.append("null");
        }
        value = value.toString();
        if (value instanceof String) {
            for (char ch : ((String) value).toCharArray()) {
                if (ch >= ' ') {
                    stuffed.append(ch);
                } else {
                    String hex = Integer.toHexString(ch);
                    stuffed.append("\\u");
                    for (int i = hex.length(); i < 4; i++) {
                        stuffed.append('0');
                    }
                    stuffed.append(hex);
                }
            }
        }
    }
}

/*
 * @(#)FormatKey.java  
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.format;

import java.io.Serializable;

/**
 * A <em>FormatKey</em> provides type-safe access to an attribute of
 * a {@link Format}.
 * <p>
 * A format key has a name, a type and a value.
 * 
 * @author Werner Randelshofer
 * @version $Id: FormatKey.java 299 2013-01-03 07:40:18Z werner $
 */
public class FormatKey<T> implements Serializable, Comparable {

    public enum MediaType {
        AUDIO,
        VIDEO,
        FILE
    }

    /**
     * The media MediaTypeKey.
     */
    public final static FormatKey<MediaType> MediaTypeKey = new FormatKey<>("mediaType", MediaType.class);

    /**
     * The EncodingKey.
     */
    public final static FormatKey<String> EncodingKey = new FormatKey<>("encoding", String.class);

    public final static String MIME_AVI = "video/avi";
    public final static String MIME_QUICKTIME = "video/quicktime";
    public final static String MIME_JAVA = "Java";

    /**
     * The mime type.
     */
    public final static FormatKey<String> MimeTypeKey = new FormatKey<>("mimeType", String.class);

    /**
     * The number of frames per second.
     */
    public final static FormatKey<Integer> FrameRateKey = new FormatKey<>("frameRate", Integer.class);

    /**
     * The interval between key frames.
     * If this value is not specified, most codecs will use {@code FrameRateKey}
     * as a hint and try to produce one key frame per second.
     */
    public final static FormatKey<Integer> KeyFrameIntervalKey = new FormatKey<>("keyFrameInterval", Integer.class);

    public static final long serialVersionUID = 1L;

    /**
     * Holds a String representation of the attribute key.
     */
    private String key;

    /**
     * Holds a pretty name. This can be null, if the value is self-explaining.
     */
    private String name;

    /** This variable is used as a "type token" so that we can check for
     * assignability of attribute values at runtime.
     */
    private Class<T> clazz;
    
    /** Comment keys are ignored when matching two media formats with each other. */
    private boolean comment;

    /** Creates a new instance with the specified attribute key, type token class,
     * default value null, and allowing null values. */
    public FormatKey(String key, Class<T> clazz) {
        this(key, key, clazz);
    }

    /** Creates a new instance with the specified attribute key, type token class,
     * default value null, and allowing null values. */
    public FormatKey(String key, String name, Class<T> clazz) {
        this(key, name, clazz, false);
    }

    /** Creates a new instance with the specified attribute key, type token class,
     * default value null, and allowing null values. */
    public FormatKey(String key, String name, Class<T> clazz, boolean comment) {
        this.key = key;
        this.name = name;
        this.clazz = clazz;
        this.comment=comment;
    }

    /**
     * Returns the key string.
     * @return key string.
     */
    public String getKey() {
        return key;
    }

    /**
     * Returns the pretty name string.
     * @return name string.
     */
    public String getName() {
        return name;
    }

    /** Returns the key string. */
    @Override
    public String toString() {
        return key;
    }

    /**
     * Returns true if the specified value is assignable with this key.
     *
     * @param value The value object.
     * @return True if assignable.
     */
    public boolean isAssignable(Object value) {
        return clazz.isInstance(value);
    }

    public boolean isComment() {
        return comment;
    }

    public Class getValueClass() {
        return clazz;
    }

    @Override
    public int compareTo(Object o) {
        return compareTo((FormatKey) o);
    }

    public int compareTo(FormatKey that) {
        return this.key.compareTo(that.key);
    }
}

/*
 * @(#)VideoFormatKeys.java  
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.format;

/**
 * Defines common format keys for video media.
 *
 * @author Werner Randelshofer
 * @version $Id: VideoFormatKeys.java 299 2013-01-03 07:40:18Z werner $
 */
public class VideoFormatKeys {
    /** Standard video ENCODING strings for use with FormatKey.Encoding. */
    public static final String ENCODING_BUFFERED_IMAGE = "image";

    /** Microsoft Device Independent Bitmap (DIB) format. */
    public static final String ENCODING_AVI_DIB = "DIB ";

    /** Microsoft Run Length format. */
    public static final String ENCODING_AVI_RLE = "RLE ";

    /** Techsmith Screen Capture format. */
    public static final String ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE = "tscc";
    public static final String COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE = "TechSmith Screen Capture";

    /** The WidthKey of a video frame. */
    public final static FormatKey<Integer> WidthKey = new FormatKey<>("dimX","width", Integer.class);

    /** The HeightKey of a video frame. */
    public final static FormatKey<Integer> HeightKey = new FormatKey<>("dimY","height", Integer.class);

    /** The number of bits per pixel. */
    public final static FormatKey<Integer> DepthKey = new FormatKey<>("dimZ","depth", Integer.class);

    /** The data class. */
    public final static FormatKey<Class> DataClassKey = new FormatKey<>("dataClass", Class.class);

    /** The compressor name. */
    public final static FormatKey<String> CompressorNameKey = new FormatKey<>("compressorName", "compressorName", String.class, true);

    /** The compressor name. */
    public final static FormatKey<Integer> CompressionLevelKey = new FormatKey<>("compressionLevel", "compressionLevel", Integer.class);

    /** Whether the frame rate must be fixed. False means variable frame rate. */
    public final static FormatKey<Boolean> FixedFrameRateKey = new FormatKey<>("fixedFrameRate", Boolean.class);

    /** Encoding quality. Value between 0 and 1. */
    public final static FormatKey<Float> QualityKey = new FormatKey<>("quality", Float.class);
}

/*
 * @(#)ByteArrayImageOutputStream.java  1.0.1  2011-01-23
 * 
 * Copyright (c) 2011 Werner Randelshofer
 * Staldenmattweg 2, Goldau, CH-6405, Switzerland.
 * All rights reserved.
 * 
 * The copyright of this software is owned by Werner Randelshofer. 
 * You may not use, copy or modify this software, except in  
 * accordance with the license agreement you entered into with  
 * Werner Randelshofer. For details see accompanying license terms.
 */
package com.videorecorder.video.io;

import java.io.OutputStream;
import javax.imageio.stream.ImageOutputStreamImpl;
import java.io.IOException;
import java.util.Arrays;
import java.nio.ByteOrder;

/**
 * This class implements an image output stream in which the data is
 * written into a byte array. The buffer automatically grows as data
 * is written to it.
 * The data can be retrieved using {@code toByteArray()}.
 * <p>
 * Closing a {@code ByteArrayImageOutputStream} has no effect. The methods in
 * this class can be called after the stream has been closed without
 * generating an {@code IOException}.
 *
 * @author Werner Randelshofer
 * @version 1.0.1 2011-01-23 Implements length method.
 * <br>1.0 2011-01-18 Created.
 */
public class ByteArrayImageOutputStream extends ImageOutputStreamImpl {

    /**
     * An array of bytes that was provided
     * by the creator of the stream. Elements <code>buf[0]</code>
     * through <code>buf[count-1]</code> are the
     * only bytes that can ever be read from the
     * stream;  element <code>buf[streamPos]</code> is
     * the next byte to be read.
     */
    protected byte buf[];
    /**
     * The index one greater than the last valid character in the input
     * stream buffer.
     * This value should always be nonnegative
     * and not larger than the length of <code>buf</code>.
     * It  is one greater than the position of
     * the last byte within <code>buf</code> that
     * can ever be read  from the input stream buffer.
     */
    protected int count;

    /** The offset to the start of the array. */
    private final int arrayOffset;

    public ByteArrayImageOutputStream(byte[] buf, ByteOrder byteOrder) {
        this(buf, 0, buf.length, byteOrder);
    }

    public ByteArrayImageOutputStream(byte[] buf, int offset, int length, ByteOrder byteOrder) {
        this.buf = buf;
        this.streamPos = offset;
        this.count = Math.min(offset + length, buf.length);
        this.arrayOffset = offset;
        this.byteOrder = byteOrder;
    }

    public ByteArrayImageOutputStream(ByteOrder byteOrder) {
        this(new byte[16],byteOrder);
    }

    /**
     * Reads the next byte of data from this input stream. The value
     * byte is returned as an <code>int</code> in the range
     * <code>0</code> to <code>255</code>. If no byte is available
     * because the end of the stream has been reached, the value
     * <code>-1</code> is returned.
     * <p>
     * This <code>read</code> method
     * cannot block.
     *
     * @return  the next byte of data, or <code>-1</code> if the end of the
     *          stream has been reached.
     */
    @Override
    public synchronized int read() throws IOException {
        flushBits();
        return (streamPos < count) ? (buf[(int) (streamPos++)] & 0xff) : -1;
    }

    /**
     * Reads up to <code>len</code> bytes of data into an array of bytes
     * from this input stream.
     * If <code>streamPos</code> equals <code>count</code>,
     * then <code>-1</code> is returned to indicate
     * end of file. Otherwise, the  number <code>k</code>
     * of bytes read is equal to the smaller of
     * <code>len</code> and <code>count-streamPos</code>.
     * If <code>k</code> is positive, then bytes
     * <code>buf[streamPos]</code> through <code>buf[streamPos+k-1]</code>
     * are copied into <code>b[off]</code>  through
     * <code>b[off+k-1]</code> in the manner performed
     * by <code>System.arraycopy</code>. The
     * value <code>k</code> is added into <code>streamPos</code>
     * and <code>k</code> is returned.
     * <p>
     * This <code>read</code> method cannot block.
     *
     * @param   b     the buffer into which the data is read.
     * @param   off   the start offset in the destination array <code>b</code>
     * @param   len   the maximum number of bytes read.
     * @return  the total number of bytes read into the buffer, or
     *          <code>-1</code> if there is no more data because the end of
     *          the stream has been reached.
     * @exception  NullPointerException If <code>b</code> is <code>null</code>.
     * @exception  IndexOutOfBoundsException If <code>off</code> is negative,
     * <code>len</code> is negative, or <code>len</code> is greater than
     * <code>b.length - off</code>
     */
    @Override
    public synchronized int read(byte b[], int off, int len) throws IOException {
        flushBits();
        if (b == null) {
            throw new NullPointerException();
        } else if (off < 0 || len < 0 || len > b.length - off) {
            throw new IndexOutOfBoundsException();
        }
        if (streamPos >= count) {
            return -1;
        }
        if (streamPos + len > count) {
            len = (int) (count - streamPos);
        }
        if (len <= 0) {
            return 0;
        }
        System.arraycopy(buf, (int) streamPos, b, off, len);
        streamPos += len;
        return len;
    }

    /**
     * Closing a <tt>ByteArrayInputStream</tt> has no effect. The methods in
     * this class can be called after the stream has been closed without
     * generating an <tt>IOException</tt>.
     * <p>
     */
    @Override
    public void close() {
        // does nothing!!
    }

    @Override
    public long getStreamPosition() throws IOException {
        checkClosed();
        return streamPos - arrayOffset;
    }

    @Override
    public void seek(long pos) throws IOException {
        checkClosed();
        flushBits();

        // This test also covers pos < 0
        if (pos < flushedPos) {
            throw new IndexOutOfBoundsException("pos < flushedPos!");
        }

        this.streamPos = pos + arrayOffset;
    }

    /**
     * Writes the specified byte to this output stream.
     *
     * @param   b   the byte to be written.
     */
    @Override
    public synchronized void write(int b) throws IOException {
        flushBits();
        long newcount = Math.max(streamPos + 1, count);
        if (newcount> Integer.MAX_VALUE) {
            throw new IndexOutOfBoundsException(newcount+" > max array size");
        }
        if (newcount > buf.length) {
            buf = Arrays.copyOf(buf, Math.max(buf.length << 1, (int) newcount));
        }
        buf[(int) streamPos++] = (byte) b;
        count = (int)newcount;
    }

    /**
     * Writes the specified byte array to this output stream.
     *
     * @param   b     the data.
     */
    @Override
    public synchronized void write(byte b[]) throws IOException {
        write(b, 0, b.length);
    }

    /**
     * Writes <code>len</code> bytes from the specified byte array
     * starting at offset <code>off</code> to this output stream.
     *
     * @param   b     the data.
     * @param   off   the start offset in the data.
     * @param   len   the number of bytes to write.
     */
    @Override
    public synchronized void write(byte b[], int off, int len) throws IOException {
        flushBits();
        if ((off < 0) || (off > b.length) || (len < 0)
                || ((off + len) > b.length) || ((off + len) < 0)) {
            throw new IndexOutOfBoundsException("off="+off+", len="+len+", b.length="+b.length);
        } else if (len == 0) {
            return;
        }
        int newcount = Math.max((int) streamPos + len, count);
        if (newcount > buf.length) {
            buf = Arrays.copyOf(buf, Math.max(buf.length << 1, newcount));
        }
        System.arraycopy(b, off, buf, (int) streamPos, len);
        streamPos += len;
        count = newcount;
    }

    /** Writes the contents of the byte array into the specified output
     * stream.
     * @param out The output stream.
     */
    public void toOutputStream(OutputStream out) throws IOException {
        out.write(buf, arrayOffset, count);
    }

    /**
     * Creates a newly allocated byte array. Its size is the current
     * size of this output stream and the valid contents of the buffer
     * have been copied into it.
     *
     * @return  the current contents of this output stream, as a byte array.
     * @see     java.io.ByteArrayOutputStream#size()
     */
    public synchronized byte[] toByteArray() {
        byte[] copy = new byte[count - arrayOffset];
        System.arraycopy(buf, arrayOffset, copy, 0, count);
        return copy;
    }

    @Override
    public long length() {
        return count - arrayOffset;
    }

    /**
     * Resets the <code>count</code> field of this byte array output
     * stream to zero, so that all currently accumulated output in the
     * output stream is discarded. The output stream can be used again,
     * reusing the already allocated buffer space.
     */
    public synchronized void clear() {
        count = arrayOffset;
        streamPos=arrayOffset;
    }
}

/*
 * @(#)SeekableByteArrayOutputStream.java
 * 
 * Copyright Â© 2010-2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.io;

import java.io.ByteArrayOutputStream;
import java.util.Arrays;

/**
 * {@code SeekableByteArrayOutputStream}.
 *
 * @author Werner Randelshofer
 * @version $Id: SeekableByteArrayOutputStream.java 299 2013-01-03 07:40:18Z werner $
 */
public class SeekableByteArrayOutputStream extends ByteArrayOutputStream {

    /**
     * The current stream position.
     */
    private int pos;

    /**
     * Creates a new byte array output stream. The buffer capacity is
     * initially 32 bytes, though its size increases if necessary.
     */
    public SeekableByteArrayOutputStream() {
	this(32);
    }

    /**
     * Creates a new byte array output stream, with a buffer capacity of
     * the specified size, in bytes.
     *
     * @param   size   the initial size.
     * @exception  IllegalArgumentException if size is negative.
     */
    public SeekableByteArrayOutputStream(int size) {
        if (size < 0) {
            throw new IllegalArgumentException("Negative initial size: " + size);
        }
	    buf = new byte[size];
    }

    /**
     * Creates a new byte array output stream, which reuses the supplied buffer.
     */
    public SeekableByteArrayOutputStream(byte[] buf) {
	this.buf = buf;
    }

    /**
     * Writes the specified byte to this byte array output stream.
     *
     * @param   b   the byte to be written.
     */
    @Override
    public synchronized void write(int b) {
	    int newcount = Math.max(pos + 1, count);
	    if (newcount > buf.length) {
            buf = Arrays.copyOf(buf, Math.max(buf.length << 1, newcount));
	    }
	    buf[pos++] = (byte)b;
	    count = newcount;
    }

    /**
     * Writes <code>len</code> bytes from the specified byte array
     * starting at offset <code>off</code> to this byte array output stream.
     *
     * @param   b     the data.
     * @param   off   the start offset in the data.
     * @param   len   the number of bytes to write.
     */
    @Override
    public synchronized void write(byte b[], int off, int len) {
	    if ((off < 0) || (off > b.length) || (len < 0) ||
            ((off + len) > b.length) || ((off + len) < 0)) {
	        throw new IndexOutOfBoundsException();
	    } else if (len == 0) {
	        return;
	    }
        int newcount = Math.max(pos+len,count);
        if (newcount > buf.length) {
            buf = Arrays.copyOf(buf, Math.max(buf.length << 1, newcount));
        }
        System.arraycopy(b, off, buf, pos, len);
        pos+=len;
        count = newcount;
    }

    /**
     * Resets the <code>count</code> field of this byte array output
     * stream to zero, so that all currently accumulated output in the
     * output stream is discarded. The output stream can be used again,
     * reusing the already allocated buffer space.
     */
    @Override
    public synchronized void reset() {
	    count = 0;
        pos=0;
    }

    /** Returns the underlying byte buffer. */
    public byte[] getBuffer() {
        return buf;
    }
}

/*
 * To change this template, choose Tools | Templates
 * and open the template in the editor.
 */
package com.videorecorder.video.nio;

import com.videorecorder.video.format.Format;
import java.util.EnumSet;

/**
 * A {@code Buffer} carries media data from one media processing unit to another.
 *
 * @author Werner Randelshofer
 * @version 1.0 2011-03-12 Created.
 */
public class Buffer {

    /** A flag mask that describes the boolean attributes for this buffer.
     */
    public EnumSet<BufferFlag> flags = EnumSet.noneOf(BufferFlag.class);

    /** The track number.
     */
    public int track;

    /** Header information, such as RTP header for this chunk. */
    public Object header;

    /** The media data. */
    public Object data;

    /** The data offset. This field is only used if {@code data} is an array. */
    public int offset;

    /** The data length. This field is only used if {@code data} is an array. */
    public int length;

    /** Duration of a sample in seconds.
     * Multiply this with {@code sampleCount} to get the buffer duration. 
     */
    public int sampleDuration;

    /** The time stamp of this buffer in seconds. */
    public int timeStamp;

    /** The format of the data in this buffer. */
    public Format format;

    /** The number of samples in the data field. */
    public int sampleCount = 1;
    
    /** Sequence number of the buffer. This can be used for debugging. */
    public long sequenceNumber;

    /** Sets all variables of this buffer to that buffer except for {@code data},
     * {@code offset}, {@code length} and {@code header}.
     */
    public void setMetaTo(Buffer that) {
        this.flags = EnumSet.copyOf(that.flags);
        // this.data = that.data;
        // this.offset = that.offset;
        // this.length = that.length;
        // this.header = that.header;
        this.track = that.track;
        this.sampleDuration = that.sampleDuration;
        this.timeStamp = that.timeStamp;
        this.format = that.format;
        this.sampleCount = that.sampleCount;
        this.format = that.format;
        this.sequenceNumber = that.sequenceNumber;
    }

    /** Returns true if the specified flag is set. */
    public boolean isFlag(BufferFlag flag) {
        return flags.contains(flag);
    }

    /** Convenience method for setting a flag. */
    public void setFlag(BufferFlag flag) {
        setFlag(flag, true);
    }

    /** Convenience method for clearing a flag. */
    public void clearFlag(BufferFlag flag) {
        setFlag(flag, false);
    }

    /** Sets or clears the specified flag. */
    public void setFlag(BufferFlag flag, boolean value) {
        if (value) {
            flags.add(flag);
        } else {
            flags.remove(flag);
        }
    }
}

/*
 * @(#)BufferFlag.java 
 * 
 * Copyright (c) 2011 Werner Randelshofer, Goldau, Switzerland.
 * All rights reserved.
 * 
 * You may not use, copy or modify this file, except in compliance with the
 * license agreement you entered into with Werner Randelshofer.
 * For details see accompanying license terms.
 */
package com.videorecorder.video.nio;

/**
 * {@code BufferFlag}.
 *
 * @author Werner Randelshofer
 * @version $Id: BufferFlag.java 299 2013-01-03 07:40:18Z werner $
 */
public enum BufferFlag {

    /** Indicates that the data in this buffer should be ignored. */
    DISCARD,

    /** Indicates that this Buffer holds an intra-coded picture, which can be 
     * decoded independently. */
    KEYFRAME,

    /** Indicates that the data in this buffer is at the end of the media. */
    END_OF_MEDIA,

    /** Indicates that the data in this buffer is used for initializing the
     * decoding queue.
     * <p>
     * This flag is used when the media time of a track is set to a non-keyframe
     * sample. Thus decoding must start at a keyframe at an earlier time.
     * <p>
     * Decoders should decode the buffer.
     * Encoders and Multiplexers should discard the buffer.
     */
    PREFETCH,

    /** Indicates that this buffer is known to have the same data as the
     * previous buffer. This may improve encoding performance. 
     */
    SAME_DATA
}

package com.videorecorder;

import net.runelite.client.config.Config;
import net.runelite.client.config.ConfigGroup;
import net.runelite.client.config.ConfigItem;
import net.runelite.client.config.ConfigSection;
import net.runelite.client.config.Keybind;
import net.runelite.client.config.Range;

@ConfigGroup("videorecorder")
public interface VideoRecorderConfig extends Config
{
	@ConfigSection(
		name = "Gameplay settings",
		description = "Gameplay related options for the video recording",
		position = 0
	)
	String sectionGameplay = "sectionGameplay";

	@ConfigItem(
		keyName = "stopOnLogout",
		name = "Stop on logout",
		description = "Whether to stop the video recording when your in-game character is logged out.",
		position = 1,
		section = sectionGameplay
	)
	default boolean stopOnLogout()
	{
		return false;
	}

	@ConfigItem(
		keyName = "excludeLoginScreen",
		name = "Exclude login screen",
		description = "Whether to pause the video recording when the login screen is displayed.",
		position = 2,
		section = sectionGameplay
	)
	default boolean excludeLoginScreen()
	{
		return false;
	}

	@ConfigSection(
		name = "Video settings",
		description = "Technical video options",
		position = 3
	)
	String sectionVideo = "sectionVideo";

	@ConfigItem(
		keyName = "includeCursor",
		name = "Include cursor",
		description = "Whether to include the cursor in the video.<br>" +
			"To use a custom cursor place a file 'cursor.png' in the '.runelite' folder.",
		position = 4,
		section = sectionVideo
	)
	default boolean includeCursor()
	{
		return true;
	}

	@Range(
		min = 1,
		max = 50
	)
	@ConfigItem(
		keyName = "framerate",
		name = "FPS",
		description = "The framerate (frames/second) for the video.",
		position = 5,
		section = sectionVideo
	)
	default int framerate()
	{
		return 25;
	}

	@Range(
		min = 1
	)
	@ConfigItem(
		keyName = "keyframeInterval",
		name = "Keyframe interval",
		description = "The interval (number of frames) between keyframes (versus delta frames).<br>" +
			"Examples:<br>" +
			"- A lower interval (e.g. 1) gives a bigger output file, but faster seeking (good for editing)<br>" +
			"- A moderate interval (e.g. 80) gives a good trade-off between output file size and seeking (recommended)<br>" +
			"- A higher interval (e.g. 50 FPS * 60 seconds = 3000) gives a smaller output file, but slower seeking (good for archiving)",
		position = 6,
		section = sectionVideo
	)
	default int keyframeInterval()
	{
		return 80;
	}

	@Range(
		min = 1,
		max = 9
	)
	@ConfigItem(
		keyName = "compressionLevel",
		name = "Compression level",
		description = "The amount of compression for each video frame.<br>" +
			"Examples:<br>" +
			"1: fast compression (bigger file size, faster seeking)<br>" +
			"6: default compression (recommended)<br>" +
			"9: high compression (smaller file size, slower seeking)",
		position = 7,
		section = sectionVideo
	)
	default int compressionLevel()
	{
		return 6;
	}

	@ConfigItem(
		keyName = "hotkeyStart",
		name = "Start video hotkey",
		description = "The hotkey that will start the video recording.<br>Alternatively use the start button in the plugin panel.",
		position = 8,
		section = sectionVideo
	)
	default Keybind hotkeyStart()
	{
		return Keybind.NOT_SET;
	}

	@ConfigItem(
		keyName = "hotkeyStop",
		name = "Stop video hotkey",
		description = "The hotkey that will stop the video recording.<br>Alternatively use the stop button in the plugin panel.",
		position = 9,
		section = sectionVideo
	)
	default Keybind hotkeyStop()
	{
		return Keybind.NOT_SET;
	}

	@ConfigItem(
		keyName = "showWarning",
		name = "Show warning",
		description = "Whether to show a warning",
		position = 10,
		hidden = true
	)
	default boolean showWarning()
	{
		return true;
	}

	@ConfigItem(
		keyName = "showWarning",
		name = "Set show warning",
		description = ""
	)
	void setShowWarning(boolean state);
}

package com.videorecorder;

import com.google.inject.Inject;
import java.awt.BorderLayout;
import java.awt.Color;
import java.awt.Dimension;
import java.awt.GridLayout;
import javax.swing.Box;
import javax.swing.JButton;
import javax.swing.JLabel;
import javax.swing.JPanel;
import javax.swing.SwingConstants;
import javax.swing.border.EmptyBorder;
import net.runelite.client.ui.ColorScheme;
import net.runelite.client.ui.PluginPanel;
import net.runelite.client.util.LinkBrowser;

public class VideoRecorderPanel extends PluginPanel
{
	private final JButton startButton = new JButton("Start");
	private final JButton stopButton = new JButton("Stop");
	private final VideoRecorderPlugin plugin;

	@Inject
	VideoRecorderPanel(VideoRecorderPlugin plugin, VideoRecorderConfig config)
	{
		this.plugin = plugin;

		setLayout(new BorderLayout());
		setBorder(new EmptyBorder(10, 10, 10, 10));
		setBackground(ColorScheme.DARK_GRAY_COLOR);

		final JPanel topPanel = new JPanel(new BorderLayout());
		topPanel.setBorder(new EmptyBorder(1, 0, 10, 0));

		final JPanel centerPanel = new JPanel();
		centerPanel.setLayout(new GridLayout(0, 1, 3, 10));

		final JPanel bottomPanel = new JPanel(new BorderLayout());
		bottomPanel.setBorder(new EmptyBorder(10, 0, 1, 0));
		bottomPanel.setLayout(new BorderLayout());

		final JPanel warningPanel = new JPanel();
		warningPanel.setBorder(new EmptyBorder(5, 5, 5, 5));
		warningPanel.setLayout(new BorderLayout());
		warningPanel.setBackground(Color.RED.darker().darker().darker());

		final JLabel warningText = new JLabel();
		warningText.setBorder(new EmptyBorder(0, 0, 5, 0));
		warningText.setForeground(Color.WHITE);
		warningText.setHorizontalAlignment(SwingConstants.CENTER);
		warningText.setText("<html><body style = 'text-align:center'>" +
			"Warning<br>Recording with this plugin while using the GPU plugin or 117HD plugin may cause your client to crash." +
			"</body></html>");

		final JButton warningButton = new JButton("Remove warning");
		warningButton.setBackground(warningPanel.getBackground().darker());
		warningButton.addActionListener(e ->
		{
			config.setShowWarning(false);
			warningPanel.setVisible(false);
		});

		warningPanel.add(warningText, BorderLayout.NORTH);
		warningPanel.add(warningButton, BorderLayout.CENTER);

		final JLabel title = new JLabel(VideoRecorderPlugin.VIDEO_RECORDER);
		title.setForeground(Color.WHITE);

		startButton.setPreferredSize(new Dimension(0, 40));
		startButton.addActionListener(e -> toggleVideo(true));

		stopButton.addActionListener(e -> toggleVideo(false));
		stopButton.setEnabled(false);

		final JButton outputButton = new JButton("Open output folder");
		outputButton.addActionListener(e -> LinkBrowser.open(VideoRecorderPlugin.VIDEO_DIR.toString()));

		topPanel.add(title);
		centerPanel.add(startButton);
		centerPanel.add(stopButton);
		bottomPanel.add(outputButton, BorderLayout.NORTH);
		if (config.showWarning())
		{
			bottomPanel.add(Box.createRigidArea(new Dimension(0, 10)), BorderLayout.CENTER);
			bottomPanel.add(warningPanel, BorderLayout.SOUTH);
		}

		add(topPanel, BorderLayout.NORTH);
		add(centerPanel, BorderLayout.CENTER);
		add(bottomPanel, BorderLayout.SOUTH);
	}

	public void toggleVideo(boolean start)
	{
		plugin.toggleVideo(start);
		startButton.setEnabled(!start);
		stopButton.setEnabled(start);
	}
}

package com.videorecorder;

import com.google.inject.Inject;
import com.google.inject.Provides;
import com.videorecorder.video.avi.AVIWriter;
import com.videorecorder.video.format.Format;
import com.videorecorder.video.format.FormatKey;
import java.awt.Dimension;
import java.awt.Graphics;
import java.awt.Image;
import java.awt.image.BufferedImage;
import java.io.File;
import java.io.IOException;
import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Date;
import java.util.concurrent.ScheduledExecutorService;
import java.util.concurrent.ScheduledThreadPoolExecutor;
import java.util.concurrent.TimeUnit;
import java.util.function.Consumer;
import javax.imageio.ImageIO;
import lombok.extern.slf4j.Slf4j;
import net.runelite.api.Client;
import net.runelite.api.GameState;
import net.runelite.api.Point;
import net.runelite.api.events.GameStateChanged;
import net.runelite.client.RuneLite;
import net.runelite.client.config.ConfigManager;
import net.runelite.client.config.RuneScapeProfileType;
import net.runelite.client.eventbus.Subscribe;
import net.runelite.client.events.ConfigChanged;
import net.runelite.client.input.KeyManager;
import net.runelite.client.plugins.Plugin;
import net.runelite.client.plugins.PluginDescriptor;
import net.runelite.client.ui.ClientToolbar;
import net.runelite.client.ui.DrawManager;
import net.runelite.client.ui.NavigationButton;
import net.runelite.client.util.HotkeyListener;
import net.runelite.client.util.ImageUtil;
import net.runelite.client.util.Text;
import static com.videorecorder.video.format.FormatKey.EncodingKey;
import static com.videorecorder.video.format.FormatKey.FrameRateKey;
import static com.videorecorder.video.format.FormatKey.KeyFrameIntervalKey;
import static com.videorecorder.video.format.FormatKey.MediaTypeKey;
import static com.videorecorder.video.format.VideoFormatKeys.CompressionLevelKey;
import static com.videorecorder.video.format.VideoFormatKeys.DepthKey;
import static com.videorecorder.video.format.VideoFormatKeys.ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE;
import static com.videorecorder.video.format.VideoFormatKeys.HeightKey;
import static com.videorecorder.video.format.VideoFormatKeys.WidthKey;

@Slf4j
@PluginDescriptor(
	name = "Video Recorder",
	description = "Capture the in-game screen as a video",
	tags = {"video", "screencast", "capture", "movie", "AVI"}
)
public class VideoRecorderPlugin extends Plugin
{
	private static final BufferedImage ICON = ImageUtil.loadImageResource(VideoRecorderPlugin.class, "/panel_icon.png");
	private static final BufferedImage CURSOR = ImageUtil.loadImageResource(VideoRecorderPlugin.class, "/cursor.png");
	private static final File CURSOR_CUSTOM = new File(RuneLite.RUNELITE_DIR, "cursor.png");
	private static final DateFormat TIME_FORMAT = new SimpleDateFormat("yyyy-MM-dd_HH-mm-ss");
	private static final String VIDEO_EXTENSION = ".avi";
	protected static final String VIDEO_RECORDER = "Video Recorder";
	protected static final File VIDEO_DIR = new File(RuneLite.RUNELITE_DIR, "videos");

	@Inject
	private Client client;

	@Inject
	private ClientToolbar clientToolbar;

	@Inject
	private DrawManager drawManager;

	@Inject
	private KeyManager keyManager;

	@Inject
	private ScheduledExecutorService imageExecutor;

	@Inject
	private VideoRecorderConfig config;

	private boolean running;
	private boolean includeCursor;
	private boolean excludeLoginScreen;
	private boolean stopOnLogout;
	private boolean loggedOut;
	private boolean lastLoggedOut = true;
	private AVIWriter video;
	private BufferedImage cursor;
	private NavigationButton navButton;
	private VideoRecorderPanel panel;
	private ScheduledThreadPoolExecutor timerExecutor;

	private final HotkeyListener hotkeyStartListener = new HotkeyListener(() -> config.hotkeyStart())
	{
		@Override
		public void hotkeyPressed()
		{
			if (!running)
			{
				panel.toggleVideo(true);
			}
			else if (config.hotkeyStart().equals(config.hotkeyStop()))
			{
				panel.toggleVideo(false);
			}
		}
	};

	private final HotkeyListener hotkeyStopListener = new HotkeyListener(() -> config.hotkeyStop())
	{
		@Override
		public void hotkeyPressed()
		{
			if (running)
			{
				panel.toggleVideo(false);
			}
		}
	};

	@Provides
	VideoRecorderConfig provideConfig(ConfigManager configManager)
	{
		return configManager.getConfig(VideoRecorderConfig.class);
	}

	@Override
	protected void startUp() throws Exception
	{
		VIDEO_DIR.mkdirs();

		includeCursor = config.includeCursor();
		excludeLoginScreen = config.excludeLoginScreen();
		stopOnLogout = config.stopOnLogout();
		if (CURSOR_CUSTOM.exists())
		{
			try
			{
				synchronized (ImageIO.class)
				{
					cursor = ImageIO.read(CURSOR_CUSTOM);
				}
			}
			catch (Exception e)
			{
				log.error("Error setting custom cursor", e);
			}
		}
		else
		{
			cursor = CURSOR;
		}

		panel = injector.getInstance(VideoRecorderPanel.class);

		navButton = NavigationButton.builder()
			.tooltip(VIDEO_RECORDER)
			.icon(ICON)
			.panel(panel)
			.priority(4)
			.build();

		clientToolbar.addNavigation(navButton);
		keyManager.registerKeyListener(hotkeyStartListener);
		keyManager.registerKeyListener(hotkeyStopListener);
	}

	@Override
	protected void shutDown() throws Exception
	{
		if (running && video != null)
		{
			panel.toggleVideo(false);
		}
		clientToolbar.removeNavigation(navButton);
		keyManager.unregisterKeyListener(hotkeyStartListener);
		keyManager.unregisterKeyListener(hotkeyStopListener);
	}

	@Subscribe
	public void onConfigChanged(ConfigChanged event)
	{
		if ("videorecorder".equals(event.getGroup()))
		{
			includeCursor = config.includeCursor();
			excludeLoginScreen = config.excludeLoginScreen();
			stopOnLogout = config.stopOnLogout();
		}
	}

	@Subscribe
	public void onGameStateChanged(GameStateChanged event)
	{
		GameState gameState = event.getGameState();
		loggedOut = GameState.LOGIN_SCREEN.equals(gameState) ||
			GameState.LOGIN_SCREEN_AUTHENTICATOR.equals(gameState) ||
			GameState.LOGGING_IN.equals(gameState) ||
			(GameState.LOADING.equals(gameState) && lastLoggedOut);
		if (stopOnLogout && loggedOut && !lastLoggedOut)
		{
			panel.toggleVideo(false);
		}
		lastLoggedOut = loggedOut;
	}

	protected void toggleVideo(boolean start)
	{
		if (start && !running)
		{
			video = null;
			running = true;

			timerExecutor = new ScheduledThreadPoolExecutor(1);
			int delay = 1000 / Math.max(1, Math.min(100, config.framerate()));
			timerExecutor.scheduleAtFixedRate(() ->
			{
				try
				{
					if (running)
					{
						if (!excludeLoginScreen || !loggedOut)
						{
							Consumer<Image> imageCallback = (img) -> imageExecutor.submit(() -> screenshot(img));
							drawManager.requestNextFrameListener(imageCallback);
						}
					}
					else
					{
						timerExecutor.shutdown();
						timerExecutor.awaitTermination(2 * delay, TimeUnit.MILLISECONDS);
						if (video != null)
						{
							video.close();
						}
					}
				}
				catch (Throwable ex)
				{
					log.warn("Error while writing video", ex);
				}
			}, 0, delay, TimeUnit.MILLISECONDS);
		}
		if (!start && running)
		{
			running = false;
		}
	}

	private void screenshot(Image image)
	{
		int width = image.getWidth(null);
		int height = image.getHeight(null);
		if (video != null)
		{
			Dimension videoSize = video.getVideoDimension(0);
			width = videoSize.width;
			height = videoSize.height;
		}
		BufferedImage frame = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);

		Graphics graphics = frame.createGraphics();
		graphics.drawImage(image, 0, 0, null);
		if (includeCursor)
		{
			Point position = client.getMouseCanvasPosition();
			int x = position.getX();
			int y = position.getY();
			if (x >= 0 && y >= 0)
			{
				graphics.drawImage(cursor, x, y, null);
			}
		}
		graphics.dispose();

		try
		{
			if (video == null)
			{
				video = new AVIWriter(createOutputFile());

				Format videoFormat = new Format(
					MediaTypeKey, FormatKey.MediaType.VIDEO,
					FrameRateKey, Math.max(1, Math.min(100, config.framerate())),
					WidthKey, frame.getWidth(),
					HeightKey, frame.getHeight(),
					EncodingKey, ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
					DepthKey, 24,
					KeyFrameIntervalKey, Math.max(0, config.keyframeInterval()),
					CompressionLevelKey, Math.max(1, Math.min(9, config.compressionLevel()))
				);

				video.addVideoTrack(videoFormat);
				video.setPalette(0, frame.getColorModel());
			}

			video.write(0, frame);
		}
		catch (IOException ex)
		{
			log.warn("Error while writing video frame", ex);
		}
	}

	private File createOutputFile()
	{
		File playerFolder;
		if (client.getLocalPlayer() != null && client.getLocalPlayer().getName() != null)
		{
			String playerDir = client.getLocalPlayer().getName();
			RuneScapeProfileType profileType = RuneScapeProfileType.getCurrent(client);
			if (profileType != RuneScapeProfileType.STANDARD)
			{
				playerDir += "-" + Text.titleCase(profileType);
			}

			playerFolder = new File(VIDEO_DIR, playerDir);
		}
		else
		{
			playerFolder = VIDEO_DIR;
		}

		playerFolder.mkdirs();

		String fileName = TIME_FORMAT.format(new Date());

		File videoFile = new File(playerFolder, fileName + VIDEO_EXTENSION);

		int i = 1;
		while (videoFile.exists())
		{
			videoFile = new File(playerFolder, fileName + String.format("(%d)", i++) + VIDEO_EXTENSION);
		}

		return videoFile;
	}
}

package com.videorecorder;

import net.runelite.client.RuneLite;
import net.runelite.client.externalplugins.ExternalPluginManager;

public class VideoRecorderPluginTest
{
	public static void main(String[] args) throws Exception
	{
		ExternalPluginManager.loadBuiltin(VideoRecorderPlugin.class);
		RuneLite.main(args);
	}
}
